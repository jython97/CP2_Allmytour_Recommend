{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Iw5Uz43igkH",
        "outputId": "f172fbfc-20f9-4054-953e-28abf385a80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VGnqkgG-ia3L"
      },
      "outputs": [],
      "source": [
        "# 필요할 것 같은 라이브러리& 모듈 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 불러오기\n",
        "order = pd.read_excel('/content/drive/MyDrive/cp2/allmytour_DB_data.xlsx', sheet_name = -1)\n",
        "ht = pd.read_excel('/content/drive/MyDrive/cp2/allmytour_DB_data.xlsx')"
      ],
      "metadata": {
        "id": "_v7eeLASZA7F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wYONGn3FjmZL",
        "outputId": "9654b948-4635-46a4-c86f-2fee04acc552"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   idx                name_kr  address_1_idx\n",
              "1    2      [소노펫클럽&리조트] 비발디파크           32.0\n",
              "2    4  소노캄 제주 (구 대명 샤인빌 리조트)           39.0\n",
              "3    6    라마다 호텔 앤 스위트 서울 남대문           11.0\n",
              "4   10              강릉 씨마크 호텔           32.0\n",
              "5   11             거제 리인스테이호텔           38.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c09966ed-32ac-4759-b3c3-02711289aeec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>name_kr</th>\n",
              "      <th>address_1_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[소노펫클럽&amp;리조트] 비발디파크</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>소노캄 제주 (구 대명 샤인빌 리조트)</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>라마다 호텔 앤 스위트 서울 남대문</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>강릉 씨마크 호텔</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>거제 리인스테이호텔</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c09966ed-32ac-4759-b3c3-02711289aeec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c09966ed-32ac-4759-b3c3-02711289aeec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c09966ed-32ac-4759-b3c3-02711289aeec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 활성화 되어 있는 숙소만 사용\n",
        "ht = ht.loc[ht.avail == 1]\n",
        "#사용할 피처 정리 \n",
        "ht = ht[['idx','name_kr','address_1_idx']]\n",
        "ht.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QLU3h3SKaOVT",
        "outputId": "0ac7c879-da90-4ca1-b375-8d18142ae32e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_idx  product_idx order_product_status\n",
              "0            10           37               cancel\n",
              "1            10           44               cancel\n",
              "2            10          197               cancel\n",
              "3            10          459               cancel\n",
              "4            11           44               cancel\n",
              "...         ...          ...                  ...\n",
              "14406    102704          276              pending\n",
              "14407    102749          276               cancel\n",
              "14408    102819            2              pending\n",
              "14409    102819            2              pending\n",
              "14410    102822            2              pending\n",
              "\n",
              "[14411 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc0645c1-6f3c-46e3-bb27-3d18d294cbce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_idx</th>\n",
              "      <th>product_idx</th>\n",
              "      <th>order_product_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>37</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>197</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>459</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>44</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14406</th>\n",
              "      <td>102704</td>\n",
              "      <td>276</td>\n",
              "      <td>pending</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14407</th>\n",
              "      <td>102749</td>\n",
              "      <td>276</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14408</th>\n",
              "      <td>102819</td>\n",
              "      <td>2</td>\n",
              "      <td>pending</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14409</th>\n",
              "      <td>102819</td>\n",
              "      <td>2</td>\n",
              "      <td>pending</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14410</th>\n",
              "      <td>102822</td>\n",
              "      <td>2</td>\n",
              "      <td>pending</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14411 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc0645c1-6f3c-46e3-bb27-3d18d294cbce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc0645c1-6f3c-46e3-bb27-3d18d294cbce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc0645c1-6f3c-46e3-bb27-3d18d294cbce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#order 사용할 피처정리\n",
        "order = order[['user_idx','product_idx','order_product_status']]\n",
        "order"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order.rename(columns={'order_product_status':'rating'}, inplace=True)\n",
        "order.drop_duplicates(subset=['user_idx', 'product_idx'], inplace=True)\n",
        "order.reset_index(drop=True, inplace=True)\n",
        "order"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "CJH33yJiaH5m",
        "outputId": "727501e7-fdba-42cc-ebf8-765828073dfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_idx  product_idx   rating\n",
              "0            10           37   cancel\n",
              "1            10           44   cancel\n",
              "2            10          197   cancel\n",
              "3            10          459   cancel\n",
              "4            11           44   cancel\n",
              "...         ...          ...      ...\n",
              "10511    102681            2  pending\n",
              "10512    102704          276  pending\n",
              "10513    102749          276   cancel\n",
              "10514    102819            2  pending\n",
              "10515    102822            2  pending\n",
              "\n",
              "[10516 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-350607de-f05c-425b-a498-de1f67887368\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_idx</th>\n",
              "      <th>product_idx</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>37</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>197</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>459</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>44</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10511</th>\n",
              "      <td>102681</td>\n",
              "      <td>2</td>\n",
              "      <td>pending</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10512</th>\n",
              "      <td>102704</td>\n",
              "      <td>276</td>\n",
              "      <td>pending</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10513</th>\n",
              "      <td>102749</td>\n",
              "      <td>276</td>\n",
              "      <td>cancel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10514</th>\n",
              "      <td>102819</td>\n",
              "      <td>2</td>\n",
              "      <td>pending</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10515</th>\n",
              "      <td>102822</td>\n",
              "      <td>2</td>\n",
              "      <td>pending</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10516 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-350607de-f05c-425b-a498-de1f67887368')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-350607de-f05c-425b-a498-de1f67887368 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-350607de-f05c-425b-a498-de1f67887368');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HylJwlfsbXI8",
        "outputId": "a62a94ea-1bd6-42e0-c1e9-4bd1644d78d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   idx                name_kr\n",
              "1    2      [소노펫클럽&리조트] 비발디파크\n",
              "2    4  소노캄 제주 (구 대명 샤인빌 리조트)\n",
              "3    6    라마다 호텔 앤 스위트 서울 남대문\n",
              "4   10              강릉 씨마크 호텔\n",
              "5   11             거제 리인스테이호텔"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dba84e1f-efc7-4629-9275-9569970cebc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>name_kr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[소노펫클럽&amp;리조트] 비발디파크</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>소노캄 제주 (구 대명 샤인빌 리조트)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>라마다 호텔 앤 스위트 서울 남대문</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>강릉 씨마크 호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>거제 리인스테이호텔</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dba84e1f-efc7-4629-9275-9569970cebc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dba84e1f-efc7-4629-9275-9569970cebc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dba84e1f-efc7-4629-9275-9569970cebc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ht_name = ht.loc[:, ['idx','name_kr']]\n",
        "ht_name.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rating 값 변환\n",
        "def rating(value):\n",
        "    if (value=='confirm') | (value=='pending') | (value=='addpay') | (value=='complete'):\n",
        "        value = 1\n",
        "    else:\n",
        "        value = 0\n",
        "    return value \n",
        "\n",
        "order['rating'] = order['rating'].apply(rating)\n",
        "order.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "2iydDdqlcee9",
        "outputId": "24af61e6-d927-48e4-f919-63534650e009"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_idx  product_idx  rating\n",
              "0        10           37       0\n",
              "1        10           44       0\n",
              "2        10          197       0\n",
              "3        10          459       0\n",
              "4        11           44       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3043e33-920c-4402-8345-85d877b97964\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_idx</th>\n",
              "      <th>product_idx</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>197</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>459</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3043e33-920c-4402-8345-85d877b97964')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3043e33-920c-4402-8345-85d877b97964 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3043e33-920c-4402-8345-85d877b97964');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order.rating.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9k8KUFUda62",
        "outputId": "ba8f517e-b93f-4d2e-8492-344e6593bd9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5301\n",
              "1    5215\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_product = order.groupby('user_idx')['product_idx'].apply(list)\n",
        "user_product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFkNkSHMdwpi",
        "outputId": "b25bca99-e267-47d2-caf2-e3b0017f06bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_idx\n",
              "10                                       [37, 44, 197, 459]\n",
              "11                                    [44, 57, 510, 78, 98]\n",
              "23                                                    [197]\n",
              "26                        [197, 265, 76, 81, 276, 2564, 37]\n",
              "48        [197, 57, 173, 76, 78, 444, 225, 29, 36, 544, ...\n",
              "                                ...                        \n",
              "102681                                                  [2]\n",
              "102704                                                [276]\n",
              "102749                                                [276]\n",
              "102819                                                  [2]\n",
              "102822                                                  [2]\n",
              "Name: product_idx, Length: 9076, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_product = user_product.reset_index()\n",
        "user_product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "R8WmqtrieN2g",
        "outputId": "7a35386e-6a47-46db-d1f8-829920979b50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      user_idx                                        product_idx\n",
              "0           10                                 [37, 44, 197, 459]\n",
              "1           11                              [44, 57, 510, 78, 98]\n",
              "2           23                                              [197]\n",
              "3           26                  [197, 265, 76, 81, 276, 2564, 37]\n",
              "4           48  [197, 57, 173, 76, 78, 444, 225, 29, 36, 544, ...\n",
              "...        ...                                                ...\n",
              "9071    102681                                                [2]\n",
              "9072    102704                                              [276]\n",
              "9073    102749                                              [276]\n",
              "9074    102819                                                [2]\n",
              "9075    102822                                                [2]\n",
              "\n",
              "[9076 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa81336e-9b82-453f-818b-366506688676\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_idx</th>\n",
              "      <th>product_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>[37, 44, 197, 459]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>[44, 57, 510, 78, 98]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>[197]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26</td>\n",
              "      <td>[197, 265, 76, 81, 276, 2564, 37]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48</td>\n",
              "      <td>[197, 57, 173, 76, 78, 444, 225, 29, 36, 544, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9071</th>\n",
              "      <td>102681</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9072</th>\n",
              "      <td>102704</td>\n",
              "      <td>[276]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9073</th>\n",
              "      <td>102749</td>\n",
              "      <td>[276]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9074</th>\n",
              "      <td>102819</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9075</th>\n",
              "      <td>102822</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9076 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa81336e-9b82-453f-818b-366506688676')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa81336e-9b82-453f-818b-366506688676 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa81336e-9b82-453f-818b-366506688676');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#자카드 유사도기반 top-k 구하기 \n",
        "def jacc_sim(user_idx):\n",
        "    sim_list = []\n",
        "    \n"
      ],
      "metadata": {
        "id": "3ACzrZrseVy2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "일단 아래로 내려오지 말아봐"
      ],
      "metadata": {
        "id": "Yan48cvDbnI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL"
      ],
      "metadata": {
        "id": "MfuPeS5sx6SS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "njWzl4Jhsntg"
      },
      "outputs": [],
      "source": [
        "#module& library\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,Embedding, Dot, Add, Flatten\n",
        "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "from tensorflow.keras.optimizers import SGD, Adamax, Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_test_split\n",
        "df_train, df_test = train_test_split(order, test_size = 0.25, random_state=29)"
      ],
      "metadata": {
        "id": "vkMKY7RdyELM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#variable \n",
        "K = 50\n",
        "#mu \n",
        "M = 9070\n",
        "N = 291\n",
        "\n",
        "\n",
        "\n",
        "#keras model \n",
        "user = Input(shape=(1,))\n",
        "item = Input(shape=(1,))\n",
        "P_embedding = Embedding(M,K, embeddings_regularizer= l2())(user)\n",
        "Q_embedding = Embedding(N,K, embeddings_regularizer= l2())(item)\n",
        "user_bias = Embedding(M,1,embeddings_regularizer=l2())(user)\n",
        "item_bias = Embedding(N,1,embeddings_regularizer=l2())(item)\n",
        "\n",
        "###Concatenate layers\n",
        "P_embedding = Flatten()(P_embedding)\n",
        "Q_embedding = Flatten()(Q_embedding)\n",
        "user_bias = Flatten()(user_bias)\n",
        "item_bias = Flatten()(item_bias)\n",
        "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias])\n",
        "\n",
        "####Newral network \n",
        "R = Dense(2048)(R)\n",
        "R = Activation('relu')(R)\n",
        "R = Dense(256)(R)\n",
        "R = Activation('relu')(R)\n",
        "R = Dense(64)(R)\n",
        "R = Activation('relu')(R)\n",
        "R = Dense(1, activation = 'sigmoid')(R)\n",
        "#R = Activation('sigmoid')(R)"
      ],
      "metadata": {
        "id": "GB1kHtonyyH8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model setting \n",
        "model = Model(inputs = [user, item], outputs=R)\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "print('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9-M7_-D0hew",
        "outputId": "c3868b99-1190-4353-9ef0-663797448678"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 50)        453500      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 50)        14550       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 1, 1)         9070        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 1, 1)         291         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 50)           0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 50)           0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1)            0           ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 1)            0           ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 102)          0           ['flatten[0][0]',                \n",
            "                                                                  'flatten_1[0][0]',              \n",
            "                                                                  'flatten_2[0][0]',              \n",
            "                                                                  'flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2048)         210944      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 2048)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          524544      ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           16448       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 64)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            65          ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,229,412\n",
            "Trainable params: 1,229,412\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SJo3W-BGzA81",
        "outputId": "d4d0c6e5-72b1-4c94-9d50-aa1148755369"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      user_idx  product_idx  rating\n",
              "8920     78741           37       0\n",
              "969       8471          265       1\n",
              "3323     42242          276       0\n",
              "5779     59827           36       1\n",
              "9469     86555           28       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f2e8470-ed64-40c1-a812-a4f92571ede2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_idx</th>\n",
              "      <th>product_idx</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8920</th>\n",
              "      <td>78741</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>8471</td>\n",
              "      <td>265</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3323</th>\n",
              "      <td>42242</td>\n",
              "      <td>276</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5779</th>\n",
              "      <td>59827</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9469</th>\n",
              "      <td>86555</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f2e8470-ed64-40c1-a812-a4f92571ede2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f2e8470-ed64-40c1-a812-a4f92571ede2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f2e8470-ed64-40c1-a812-a4f92571ede2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7IxoMgA1Vc-",
        "outputId": "61b2de93-7e2d-4e92-b732-9aa88a7f7daa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_idx       int64\n",
              "product_idx    int64\n",
              "rating         int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['product_idx'] = df_train['product_idx'].astype(float)\n",
        "df_test['product_idx'] = df_test['product_idx'].astype(float)\n",
        "df_train['user_idx'] = df_train['user_idx'].astype(float)\n",
        "df_test['user_idx'] = df_test['user_idx'].astype(float)\n",
        "df_train['rating'] = df_train['rating'].astype(float)\n",
        "df_test['rating'] = df_test['rating'].astype(float)"
      ],
      "metadata": {
        "id": "QScR--pHWE5U"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model fitting \n",
        "result = model.fit(\n",
        "    x = [df_train.user_idx.values, df_train.product_idx.values],\n",
        "    y = df_train.rating.values,\n",
        "    epochs=1000,\n",
        "    batch_size=64,\n",
        "    validation_data=(\n",
        "        [df_test.user_idx.values, df_test.product_idx.values],\n",
        "        df_test.rating.values\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBvgP_8BzUIj",
        "outputId": "3d5f968e-6b46-4911-a826-b7b7c47ce39b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "124/124 [==============================] - 5s 7ms/step - loss: 1.1377 - accuracy: 0.5583 - val_loss: 0.6830 - val_accuracy: 0.5656\n",
            "Epoch 2/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6826 - accuracy: 0.5665 - val_loss: 0.6824 - val_accuracy: 0.5725\n",
            "Epoch 3/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6779 - accuracy: 0.5811 - val_loss: 0.6826 - val_accuracy: 0.5709\n",
            "Epoch 4/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6787 - accuracy: 0.5821 - val_loss: 0.6875 - val_accuracy: 0.5702\n",
            "Epoch 5/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6757 - accuracy: 0.5939 - val_loss: 0.6952 - val_accuracy: 0.5683\n",
            "Epoch 6/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6675 - accuracy: 0.6015 - val_loss: 0.6972 - val_accuracy: 0.5709\n",
            "Epoch 7/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6653 - accuracy: 0.6040 - val_loss: 0.6970 - val_accuracy: 0.5706\n",
            "Epoch 8/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6551 - accuracy: 0.5996 - val_loss: 0.7220 - val_accuracy: 0.5759\n",
            "Epoch 9/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6513 - accuracy: 0.6061 - val_loss: 0.7213 - val_accuracy: 0.5706\n",
            "Epoch 10/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6478 - accuracy: 0.6047 - val_loss: 0.7163 - val_accuracy: 0.5626\n",
            "Epoch 11/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6470 - accuracy: 0.6054 - val_loss: 0.7400 - val_accuracy: 0.5645\n",
            "Epoch 12/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6446 - accuracy: 0.6087 - val_loss: 0.7312 - val_accuracy: 0.5576\n",
            "Epoch 13/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6429 - accuracy: 0.6067 - val_loss: 0.7200 - val_accuracy: 0.5679\n",
            "Epoch 14/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6436 - accuracy: 0.6069 - val_loss: 0.7302 - val_accuracy: 0.5637\n",
            "Epoch 15/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6430 - accuracy: 0.6089 - val_loss: 0.7444 - val_accuracy: 0.5637\n",
            "Epoch 16/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6447 - accuracy: 0.6086 - val_loss: 0.7384 - val_accuracy: 0.5698\n",
            "Epoch 17/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6408 - accuracy: 0.6097 - val_loss: 0.7252 - val_accuracy: 0.5736\n",
            "Epoch 18/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6411 - accuracy: 0.6071 - val_loss: 0.7305 - val_accuracy: 0.5740\n",
            "Epoch 19/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6431 - accuracy: 0.6110 - val_loss: 0.7362 - val_accuracy: 0.5607\n",
            "Epoch 20/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6417 - accuracy: 0.6121 - val_loss: 0.7295 - val_accuracy: 0.5656\n",
            "Epoch 21/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6424 - accuracy: 0.6066 - val_loss: 0.7307 - val_accuracy: 0.5675\n",
            "Epoch 22/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6420 - accuracy: 0.6108 - val_loss: 0.7550 - val_accuracy: 0.5744\n",
            "Epoch 23/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6472 - accuracy: 0.6062 - val_loss: 0.7060 - val_accuracy: 0.5751\n",
            "Epoch 24/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6391 - accuracy: 0.6059 - val_loss: 0.7321 - val_accuracy: 0.5603\n",
            "Epoch 25/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6390 - accuracy: 0.6135 - val_loss: 0.7342 - val_accuracy: 0.5637\n",
            "Epoch 26/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6358 - accuracy: 0.6096 - val_loss: 0.7297 - val_accuracy: 0.5679\n",
            "Epoch 27/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6366 - accuracy: 0.6115 - val_loss: 0.7313 - val_accuracy: 0.5717\n",
            "Epoch 28/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6373 - accuracy: 0.6105 - val_loss: 0.7348 - val_accuracy: 0.5668\n",
            "Epoch 29/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6352 - accuracy: 0.6120 - val_loss: 0.7247 - val_accuracy: 0.5664\n",
            "Epoch 30/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6347 - accuracy: 0.6133 - val_loss: 0.7432 - val_accuracy: 0.5630\n",
            "Epoch 31/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6375 - accuracy: 0.6100 - val_loss: 0.7374 - val_accuracy: 0.5633\n",
            "Epoch 32/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.6109 - val_loss: 0.7384 - val_accuracy: 0.5610\n",
            "Epoch 33/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6412 - accuracy: 0.6089 - val_loss: 0.7301 - val_accuracy: 0.5641\n",
            "Epoch 34/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6406 - accuracy: 0.6105 - val_loss: 0.7254 - val_accuracy: 0.5630\n",
            "Epoch 35/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6343 - accuracy: 0.6096 - val_loss: 0.7295 - val_accuracy: 0.5679\n",
            "Epoch 36/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6319 - accuracy: 0.6133 - val_loss: 0.7219 - val_accuracy: 0.5618\n",
            "Epoch 37/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6338 - accuracy: 0.6125 - val_loss: 0.7306 - val_accuracy: 0.5618\n",
            "Epoch 38/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6385 - accuracy: 0.6121 - val_loss: 0.7274 - val_accuracy: 0.5706\n",
            "Epoch 39/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6339 - accuracy: 0.6090 - val_loss: 0.7381 - val_accuracy: 0.5656\n",
            "Epoch 40/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6290 - accuracy: 0.6114 - val_loss: 0.7347 - val_accuracy: 0.5622\n",
            "Epoch 41/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6310 - accuracy: 0.6129 - val_loss: 0.7433 - val_accuracy: 0.5694\n",
            "Epoch 42/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6342 - accuracy: 0.6089 - val_loss: 0.7608 - val_accuracy: 0.5588\n",
            "Epoch 43/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6347 - accuracy: 0.6142 - val_loss: 0.7501 - val_accuracy: 0.5565\n",
            "Epoch 44/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.6052 - val_loss: 0.7372 - val_accuracy: 0.5622\n",
            "Epoch 45/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6390 - accuracy: 0.6119 - val_loss: 0.7280 - val_accuracy: 0.5614\n",
            "Epoch 46/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6376 - accuracy: 0.6124 - val_loss: 0.7472 - val_accuracy: 0.5649\n",
            "Epoch 47/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6333 - accuracy: 0.6115 - val_loss: 0.7343 - val_accuracy: 0.5656\n",
            "Epoch 48/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6337 - accuracy: 0.6127 - val_loss: 0.7309 - val_accuracy: 0.5660\n",
            "Epoch 49/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6310 - accuracy: 0.6139 - val_loss: 0.7292 - val_accuracy: 0.5603\n",
            "Epoch 50/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6379 - accuracy: 0.6114 - val_loss: 0.7525 - val_accuracy: 0.5668\n",
            "Epoch 51/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6368 - accuracy: 0.6134 - val_loss: 0.7293 - val_accuracy: 0.5622\n",
            "Epoch 52/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6361 - accuracy: 0.6118 - val_loss: 0.7447 - val_accuracy: 0.5652\n",
            "Epoch 53/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6342 - accuracy: 0.6130 - val_loss: 0.7416 - val_accuracy: 0.5630\n",
            "Epoch 54/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6310 - accuracy: 0.6135 - val_loss: 0.7506 - val_accuracy: 0.5656\n",
            "Epoch 55/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.6156 - val_loss: 0.7325 - val_accuracy: 0.5656\n",
            "Epoch 56/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.6157 - val_loss: 0.7211 - val_accuracy: 0.5660\n",
            "Epoch 57/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6309 - accuracy: 0.6066 - val_loss: 0.7280 - val_accuracy: 0.5637\n",
            "Epoch 58/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.6133 - val_loss: 0.7214 - val_accuracy: 0.5645\n",
            "Epoch 59/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6321 - accuracy: 0.6116 - val_loss: 0.7181 - val_accuracy: 0.5656\n",
            "Epoch 60/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6321 - accuracy: 0.6157 - val_loss: 0.7281 - val_accuracy: 0.5668\n",
            "Epoch 61/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6287 - accuracy: 0.6111 - val_loss: 0.7365 - val_accuracy: 0.5664\n",
            "Epoch 62/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6290 - accuracy: 0.6125 - val_loss: 0.7449 - val_accuracy: 0.5732\n",
            "Epoch 63/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6400 - accuracy: 0.6077 - val_loss: 0.7105 - val_accuracy: 0.5721\n",
            "Epoch 64/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6493 - accuracy: 0.6073 - val_loss: 0.7677 - val_accuracy: 0.5656\n",
            "Epoch 65/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6402 - accuracy: 0.6118 - val_loss: 0.7617 - val_accuracy: 0.5633\n",
            "Epoch 66/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.6123 - val_loss: 0.7424 - val_accuracy: 0.5618\n",
            "Epoch 67/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6316 - accuracy: 0.6129 - val_loss: 0.7346 - val_accuracy: 0.5698\n",
            "Epoch 68/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6309 - accuracy: 0.6154 - val_loss: 0.7532 - val_accuracy: 0.5668\n",
            "Epoch 69/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6262 - accuracy: 0.6116 - val_loss: 0.7660 - val_accuracy: 0.5732\n",
            "Epoch 70/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.6147 - val_loss: 0.7554 - val_accuracy: 0.5725\n",
            "Epoch 71/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6154 - val_loss: 0.7644 - val_accuracy: 0.5690\n",
            "Epoch 72/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6294 - accuracy: 0.6128 - val_loss: 0.7450 - val_accuracy: 0.5614\n",
            "Epoch 73/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6414 - accuracy: 0.6100 - val_loss: 0.7413 - val_accuracy: 0.5637\n",
            "Epoch 74/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6376 - accuracy: 0.6108 - val_loss: 0.7535 - val_accuracy: 0.5641\n",
            "Epoch 75/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.6123 - val_loss: 0.7391 - val_accuracy: 0.5641\n",
            "Epoch 76/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6284 - accuracy: 0.6118 - val_loss: 0.7437 - val_accuracy: 0.5671\n",
            "Epoch 77/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6261 - accuracy: 0.6149 - val_loss: 0.7540 - val_accuracy: 0.5645\n",
            "Epoch 78/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6292 - accuracy: 0.6144 - val_loss: 0.7395 - val_accuracy: 0.5687\n",
            "Epoch 79/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6264 - accuracy: 0.6119 - val_loss: 0.7407 - val_accuracy: 0.5679\n",
            "Epoch 80/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6312 - accuracy: 0.6146 - val_loss: 0.7478 - val_accuracy: 0.5728\n",
            "Epoch 81/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6348 - accuracy: 0.6152 - val_loss: 0.7479 - val_accuracy: 0.5622\n",
            "Epoch 82/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6304 - accuracy: 0.6129 - val_loss: 0.7519 - val_accuracy: 0.5660\n",
            "Epoch 83/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6325 - accuracy: 0.6128 - val_loss: 0.7664 - val_accuracy: 0.5706\n",
            "Epoch 84/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6335 - accuracy: 0.6115 - val_loss: 0.7833 - val_accuracy: 0.5630\n",
            "Epoch 85/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6302 - accuracy: 0.6147 - val_loss: 0.7698 - val_accuracy: 0.5637\n",
            "Epoch 86/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6091 - val_loss: 0.7442 - val_accuracy: 0.5679\n",
            "Epoch 87/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.6157 - val_loss: 0.7361 - val_accuracy: 0.5630\n",
            "Epoch 88/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6271 - accuracy: 0.6137 - val_loss: 0.7595 - val_accuracy: 0.5728\n",
            "Epoch 89/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6274 - accuracy: 0.6137 - val_loss: 0.7493 - val_accuracy: 0.5656\n",
            "Epoch 90/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6313 - accuracy: 0.6129 - val_loss: 0.7398 - val_accuracy: 0.5633\n",
            "Epoch 91/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6368 - accuracy: 0.6099 - val_loss: 0.7467 - val_accuracy: 0.5622\n",
            "Epoch 92/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6402 - accuracy: 0.6113 - val_loss: 0.7328 - val_accuracy: 0.5683\n",
            "Epoch 93/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6340 - accuracy: 0.6139 - val_loss: 0.7061 - val_accuracy: 0.5626\n",
            "Epoch 94/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6321 - accuracy: 0.6148 - val_loss: 0.7415 - val_accuracy: 0.5671\n",
            "Epoch 95/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6263 - accuracy: 0.6146 - val_loss: 0.7487 - val_accuracy: 0.5664\n",
            "Epoch 96/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6286 - accuracy: 0.6157 - val_loss: 0.7228 - val_accuracy: 0.5668\n",
            "Epoch 97/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6296 - accuracy: 0.6158 - val_loss: 0.7583 - val_accuracy: 0.5645\n",
            "Epoch 98/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6273 - accuracy: 0.6163 - val_loss: 0.7305 - val_accuracy: 0.5660\n",
            "Epoch 99/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6252 - accuracy: 0.6137 - val_loss: 0.7347 - val_accuracy: 0.5630\n",
            "Epoch 100/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6306 - accuracy: 0.6147 - val_loss: 0.7528 - val_accuracy: 0.5618\n",
            "Epoch 101/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6283 - accuracy: 0.6142 - val_loss: 0.7684 - val_accuracy: 0.5713\n",
            "Epoch 102/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6247 - accuracy: 0.6119 - val_loss: 0.7526 - val_accuracy: 0.5664\n",
            "Epoch 103/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6275 - accuracy: 0.6175 - val_loss: 0.7542 - val_accuracy: 0.5622\n",
            "Epoch 104/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6396 - accuracy: 0.6102 - val_loss: 0.7812 - val_accuracy: 0.5747\n",
            "Epoch 105/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6381 - accuracy: 0.6142 - val_loss: 0.7553 - val_accuracy: 0.5622\n",
            "Epoch 106/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6338 - accuracy: 0.6162 - val_loss: 0.7378 - val_accuracy: 0.5660\n",
            "Epoch 107/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6316 - accuracy: 0.6140 - val_loss: 0.7447 - val_accuracy: 0.5668\n",
            "Epoch 108/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6288 - accuracy: 0.6156 - val_loss: 0.7381 - val_accuracy: 0.5614\n",
            "Epoch 109/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6256 - accuracy: 0.6152 - val_loss: 0.7551 - val_accuracy: 0.5698\n",
            "Epoch 110/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6245 - accuracy: 0.6140 - val_loss: 0.7482 - val_accuracy: 0.5618\n",
            "Epoch 111/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.6148 - val_loss: 0.7409 - val_accuracy: 0.5630\n",
            "Epoch 112/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6259 - accuracy: 0.6167 - val_loss: 0.7355 - val_accuracy: 0.5687\n",
            "Epoch 113/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6288 - accuracy: 0.6156 - val_loss: 0.7797 - val_accuracy: 0.5607\n",
            "Epoch 114/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6339 - accuracy: 0.6172 - val_loss: 0.7746 - val_accuracy: 0.5683\n",
            "Epoch 115/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6294 - accuracy: 0.6143 - val_loss: 0.7561 - val_accuracy: 0.5683\n",
            "Epoch 116/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6285 - accuracy: 0.6161 - val_loss: 0.7540 - val_accuracy: 0.5687\n",
            "Epoch 117/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6443 - accuracy: 0.6129 - val_loss: 0.7631 - val_accuracy: 0.5645\n",
            "Epoch 118/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6359 - accuracy: 0.6149 - val_loss: 0.7433 - val_accuracy: 0.5664\n",
            "Epoch 119/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6264 - accuracy: 0.6121 - val_loss: 0.7678 - val_accuracy: 0.5641\n",
            "Epoch 120/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6279 - accuracy: 0.6138 - val_loss: 0.7336 - val_accuracy: 0.5622\n",
            "Epoch 121/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6265 - accuracy: 0.6160 - val_loss: 0.7425 - val_accuracy: 0.5626\n",
            "Epoch 122/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6264 - accuracy: 0.6156 - val_loss: 0.7427 - val_accuracy: 0.5622\n",
            "Epoch 123/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6248 - accuracy: 0.6132 - val_loss: 0.7310 - val_accuracy: 0.5626\n",
            "Epoch 124/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6291 - accuracy: 0.6185 - val_loss: 0.7525 - val_accuracy: 0.5641\n",
            "Epoch 125/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6256 - accuracy: 0.6151 - val_loss: 0.7527 - val_accuracy: 0.5675\n",
            "Epoch 126/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6158 - val_loss: 0.7539 - val_accuracy: 0.5668\n",
            "Epoch 127/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6146 - val_loss: 0.7131 - val_accuracy: 0.5660\n",
            "Epoch 128/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6351 - accuracy: 0.6129 - val_loss: 0.7287 - val_accuracy: 0.5668\n",
            "Epoch 129/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6293 - accuracy: 0.6151 - val_loss: 0.7432 - val_accuracy: 0.5664\n",
            "Epoch 130/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.6158 - val_loss: 0.7413 - val_accuracy: 0.5668\n",
            "Epoch 131/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6240 - accuracy: 0.6158 - val_loss: 0.7623 - val_accuracy: 0.5671\n",
            "Epoch 132/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6238 - accuracy: 0.6137 - val_loss: 0.7636 - val_accuracy: 0.5706\n",
            "Epoch 133/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.6161 - val_loss: 0.7652 - val_accuracy: 0.5637\n",
            "Epoch 134/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6252 - accuracy: 0.6160 - val_loss: 0.7496 - val_accuracy: 0.5755\n",
            "Epoch 135/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6300 - accuracy: 0.6144 - val_loss: 0.7454 - val_accuracy: 0.5614\n",
            "Epoch 136/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6334 - accuracy: 0.6127 - val_loss: 0.7535 - val_accuracy: 0.5664\n",
            "Epoch 137/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6336 - accuracy: 0.6187 - val_loss: 0.7384 - val_accuracy: 0.5668\n",
            "Epoch 138/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6326 - accuracy: 0.6137 - val_loss: 0.7331 - val_accuracy: 0.5660\n",
            "Epoch 139/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6343 - accuracy: 0.6096 - val_loss: 0.7239 - val_accuracy: 0.5618\n",
            "Epoch 140/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6281 - accuracy: 0.6160 - val_loss: 0.7462 - val_accuracy: 0.5652\n",
            "Epoch 141/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6242 - accuracy: 0.6170 - val_loss: 0.7450 - val_accuracy: 0.5656\n",
            "Epoch 142/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6273 - accuracy: 0.6146 - val_loss: 0.7340 - val_accuracy: 0.5759\n",
            "Epoch 143/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6254 - accuracy: 0.6180 - val_loss: 0.7535 - val_accuracy: 0.5713\n",
            "Epoch 144/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6247 - accuracy: 0.6139 - val_loss: 0.7466 - val_accuracy: 0.5755\n",
            "Epoch 145/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6247 - accuracy: 0.6163 - val_loss: 0.7469 - val_accuracy: 0.5660\n",
            "Epoch 146/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.6158 - val_loss: 0.7469 - val_accuracy: 0.5664\n",
            "Epoch 147/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.6184 - val_loss: 0.7455 - val_accuracy: 0.5664\n",
            "Epoch 148/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6424 - accuracy: 0.6133 - val_loss: 0.7746 - val_accuracy: 0.5675\n",
            "Epoch 149/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6365 - accuracy: 0.6170 - val_loss: 0.7893 - val_accuracy: 0.5641\n",
            "Epoch 150/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6324 - accuracy: 0.6138 - val_loss: 0.7679 - val_accuracy: 0.5679\n",
            "Epoch 151/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6281 - accuracy: 0.6143 - val_loss: 0.7501 - val_accuracy: 0.5664\n",
            "Epoch 152/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6162 - val_loss: 0.7461 - val_accuracy: 0.5671\n",
            "Epoch 153/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6277 - accuracy: 0.6167 - val_loss: 0.7626 - val_accuracy: 0.5660\n",
            "Epoch 154/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6258 - accuracy: 0.6177 - val_loss: 0.7607 - val_accuracy: 0.5641\n",
            "Epoch 155/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.6124 - val_loss: 0.7438 - val_accuracy: 0.5671\n",
            "Epoch 156/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6288 - accuracy: 0.6144 - val_loss: 0.7362 - val_accuracy: 0.5641\n",
            "Epoch 157/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6309 - accuracy: 0.6108 - val_loss: 0.7678 - val_accuracy: 0.5702\n",
            "Epoch 158/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6256 - accuracy: 0.6121 - val_loss: 0.7442 - val_accuracy: 0.5706\n",
            "Epoch 159/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6252 - accuracy: 0.6157 - val_loss: 0.7437 - val_accuracy: 0.5652\n",
            "Epoch 160/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6243 - accuracy: 0.6130 - val_loss: 0.7713 - val_accuracy: 0.5671\n",
            "Epoch 161/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6222 - accuracy: 0.6143 - val_loss: 0.7731 - val_accuracy: 0.5645\n",
            "Epoch 162/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6268 - accuracy: 0.6177 - val_loss: 0.7385 - val_accuracy: 0.5660\n",
            "Epoch 163/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.6151 - val_loss: 0.7521 - val_accuracy: 0.5649\n",
            "Epoch 164/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6325 - accuracy: 0.6113 - val_loss: 0.7548 - val_accuracy: 0.5652\n",
            "Epoch 165/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6243 - accuracy: 0.6146 - val_loss: 0.7491 - val_accuracy: 0.5664\n",
            "Epoch 166/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.6180 - val_loss: 0.7503 - val_accuracy: 0.5641\n",
            "Epoch 167/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6209 - accuracy: 0.6161 - val_loss: 0.7181 - val_accuracy: 0.5664\n",
            "Epoch 168/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6222 - accuracy: 0.6142 - val_loss: 0.7469 - val_accuracy: 0.5664\n",
            "Epoch 169/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6283 - accuracy: 0.6162 - val_loss: 0.7535 - val_accuracy: 0.5660\n",
            "Epoch 170/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6258 - accuracy: 0.6189 - val_loss: 0.7647 - val_accuracy: 0.5664\n",
            "Epoch 171/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.6173 - val_loss: 0.7617 - val_accuracy: 0.5664\n",
            "Epoch 172/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.6168 - val_loss: 0.7574 - val_accuracy: 0.5637\n",
            "Epoch 173/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6426 - accuracy: 0.6075 - val_loss: 0.7670 - val_accuracy: 0.5637\n",
            "Epoch 174/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6366 - accuracy: 0.6111 - val_loss: 0.7643 - val_accuracy: 0.5641\n",
            "Epoch 175/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6283 - accuracy: 0.6149 - val_loss: 0.7493 - val_accuracy: 0.5614\n",
            "Epoch 176/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6254 - accuracy: 0.6144 - val_loss: 0.7553 - val_accuracy: 0.5633\n",
            "Epoch 177/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6245 - accuracy: 0.6134 - val_loss: 0.7768 - val_accuracy: 0.5664\n",
            "Epoch 178/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6217 - accuracy: 0.6161 - val_loss: 0.7778 - val_accuracy: 0.5698\n",
            "Epoch 179/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.6148 - val_loss: 0.7510 - val_accuracy: 0.5637\n",
            "Epoch 180/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6318 - accuracy: 0.6133 - val_loss: 0.7520 - val_accuracy: 0.5652\n",
            "Epoch 181/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6252 - accuracy: 0.6184 - val_loss: 0.7404 - val_accuracy: 0.5687\n",
            "Epoch 182/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6261 - accuracy: 0.6129 - val_loss: 0.7515 - val_accuracy: 0.5652\n",
            "Epoch 183/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6152 - val_loss: 0.7651 - val_accuracy: 0.5660\n",
            "Epoch 184/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6190 - val_loss: 0.7568 - val_accuracy: 0.5671\n",
            "Epoch 185/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.6179 - val_loss: 0.7672 - val_accuracy: 0.5664\n",
            "Epoch 186/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6352 - accuracy: 0.6127 - val_loss: 0.7473 - val_accuracy: 0.5702\n",
            "Epoch 187/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6326 - accuracy: 0.6149 - val_loss: 0.7397 - val_accuracy: 0.5641\n",
            "Epoch 188/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6330 - accuracy: 0.6108 - val_loss: 0.7785 - val_accuracy: 0.5668\n",
            "Epoch 189/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6256 - accuracy: 0.6162 - val_loss: 0.7886 - val_accuracy: 0.5633\n",
            "Epoch 190/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.6171 - val_loss: 0.7810 - val_accuracy: 0.5664\n",
            "Epoch 191/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6215 - accuracy: 0.6162 - val_loss: 0.7881 - val_accuracy: 0.5664\n",
            "Epoch 192/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.6151 - val_loss: 0.8075 - val_accuracy: 0.5622\n",
            "Epoch 193/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6203 - val_loss: 0.7627 - val_accuracy: 0.5668\n",
            "Epoch 194/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6238 - accuracy: 0.6160 - val_loss: 0.7867 - val_accuracy: 0.5660\n",
            "Epoch 195/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6204 - accuracy: 0.6172 - val_loss: 0.7864 - val_accuracy: 0.5706\n",
            "Epoch 196/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6353 - accuracy: 0.6140 - val_loss: 0.7910 - val_accuracy: 0.5664\n",
            "Epoch 197/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6303 - accuracy: 0.6138 - val_loss: 0.7609 - val_accuracy: 0.5633\n",
            "Epoch 198/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.6171 - val_loss: 0.7626 - val_accuracy: 0.5622\n",
            "Epoch 199/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6202 - accuracy: 0.6172 - val_loss: 0.7730 - val_accuracy: 0.5622\n",
            "Epoch 200/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6192 - val_loss: 0.7429 - val_accuracy: 0.5626\n",
            "Epoch 201/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.6228 - val_loss: 0.7433 - val_accuracy: 0.5622\n",
            "Epoch 202/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.6179 - val_loss: 0.7719 - val_accuracy: 0.5622\n",
            "Epoch 203/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6184 - val_loss: 0.7493 - val_accuracy: 0.5622\n",
            "Epoch 204/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6201 - accuracy: 0.6198 - val_loss: 0.7477 - val_accuracy: 0.5626\n",
            "Epoch 205/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.6194 - val_loss: 0.7567 - val_accuracy: 0.5614\n",
            "Epoch 206/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6189 - val_loss: 0.7663 - val_accuracy: 0.5641\n",
            "Epoch 207/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6225 - accuracy: 0.6138 - val_loss: 0.7363 - val_accuracy: 0.5683\n",
            "Epoch 208/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6231 - accuracy: 0.6143 - val_loss: 0.7617 - val_accuracy: 0.5630\n",
            "Epoch 209/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.6170 - val_loss: 0.7356 - val_accuracy: 0.5622\n",
            "Epoch 210/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6162 - val_loss: 0.7701 - val_accuracy: 0.5595\n",
            "Epoch 211/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.6209 - val_loss: 0.7537 - val_accuracy: 0.5618\n",
            "Epoch 212/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6248 - accuracy: 0.6154 - val_loss: 0.7647 - val_accuracy: 0.5668\n",
            "Epoch 213/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.6172 - val_loss: 0.7654 - val_accuracy: 0.5637\n",
            "Epoch 214/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6140 - val_loss: 0.7882 - val_accuracy: 0.5630\n",
            "Epoch 215/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6225 - accuracy: 0.6129 - val_loss: 0.7637 - val_accuracy: 0.5641\n",
            "Epoch 216/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6248 - accuracy: 0.6176 - val_loss: 0.7498 - val_accuracy: 0.5660\n",
            "Epoch 217/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6222 - accuracy: 0.6138 - val_loss: 0.7839 - val_accuracy: 0.5675\n",
            "Epoch 218/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6214 - accuracy: 0.6208 - val_loss: 0.7853 - val_accuracy: 0.5652\n",
            "Epoch 219/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6235 - accuracy: 0.6203 - val_loss: 0.7445 - val_accuracy: 0.5645\n",
            "Epoch 220/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6191 - val_loss: 0.7373 - val_accuracy: 0.5671\n",
            "Epoch 221/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6271 - accuracy: 0.6167 - val_loss: 0.7509 - val_accuracy: 0.5626\n",
            "Epoch 222/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.6184 - val_loss: 0.7543 - val_accuracy: 0.5664\n",
            "Epoch 223/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.6203 - val_loss: 0.7621 - val_accuracy: 0.5671\n",
            "Epoch 224/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.6205 - val_loss: 0.7679 - val_accuracy: 0.5671\n",
            "Epoch 225/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6191 - val_loss: 0.7615 - val_accuracy: 0.5626\n",
            "Epoch 226/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6181 - val_loss: 0.7658 - val_accuracy: 0.5622\n",
            "Epoch 227/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.6194 - val_loss: 0.7419 - val_accuracy: 0.5630\n",
            "Epoch 228/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6227 - accuracy: 0.6144 - val_loss: 0.7797 - val_accuracy: 0.5607\n",
            "Epoch 229/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6204 - val_loss: 0.7616 - val_accuracy: 0.5709\n",
            "Epoch 230/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6206 - accuracy: 0.6210 - val_loss: 0.7511 - val_accuracy: 0.5614\n",
            "Epoch 231/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6203 - val_loss: 0.7382 - val_accuracy: 0.5610\n",
            "Epoch 232/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6199 - val_loss: 0.7604 - val_accuracy: 0.5660\n",
            "Epoch 233/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.6189 - val_loss: 0.7759 - val_accuracy: 0.5656\n",
            "Epoch 234/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6243 - accuracy: 0.6170 - val_loss: 0.7619 - val_accuracy: 0.5660\n",
            "Epoch 235/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6272 - accuracy: 0.6189 - val_loss: 0.7678 - val_accuracy: 0.5610\n",
            "Epoch 236/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6323 - accuracy: 0.6152 - val_loss: 0.7657 - val_accuracy: 0.5614\n",
            "Epoch 237/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6307 - accuracy: 0.6175 - val_loss: 0.7527 - val_accuracy: 0.5668\n",
            "Epoch 238/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6288 - accuracy: 0.6158 - val_loss: 0.7584 - val_accuracy: 0.5618\n",
            "Epoch 239/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6172 - val_loss: 0.7686 - val_accuracy: 0.5633\n",
            "Epoch 240/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6192 - val_loss: 0.7561 - val_accuracy: 0.5633\n",
            "Epoch 241/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.6177 - val_loss: 0.7714 - val_accuracy: 0.5633\n",
            "Epoch 242/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6209 - accuracy: 0.6184 - val_loss: 0.7481 - val_accuracy: 0.5633\n",
            "Epoch 243/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6330 - accuracy: 0.6129 - val_loss: 0.7335 - val_accuracy: 0.5630\n",
            "Epoch 244/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6167 - val_loss: 0.7470 - val_accuracy: 0.5690\n",
            "Epoch 245/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6233 - accuracy: 0.6172 - val_loss: 0.8095 - val_accuracy: 0.5694\n",
            "Epoch 246/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6196 - val_loss: 0.7864 - val_accuracy: 0.5668\n",
            "Epoch 247/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6215 - accuracy: 0.6189 - val_loss: 0.7757 - val_accuracy: 0.5664\n",
            "Epoch 248/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6179 - accuracy: 0.6186 - val_loss: 0.7824 - val_accuracy: 0.5664\n",
            "Epoch 249/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6187 - val_loss: 0.7596 - val_accuracy: 0.5713\n",
            "Epoch 250/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6251 - accuracy: 0.6190 - val_loss: 0.7661 - val_accuracy: 0.5633\n",
            "Epoch 251/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6246 - accuracy: 0.6192 - val_loss: 0.7943 - val_accuracy: 0.5622\n",
            "Epoch 252/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6229 - accuracy: 0.6186 - val_loss: 0.7863 - val_accuracy: 0.5694\n",
            "Epoch 253/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6154 - val_loss: 0.7665 - val_accuracy: 0.5690\n",
            "Epoch 254/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6129 - val_loss: 0.7667 - val_accuracy: 0.5614\n",
            "Epoch 255/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6259 - accuracy: 0.6175 - val_loss: 0.7415 - val_accuracy: 0.5607\n",
            "Epoch 256/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6464 - accuracy: 0.6102 - val_loss: 0.7608 - val_accuracy: 0.5671\n",
            "Epoch 257/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6370 - accuracy: 0.6171 - val_loss: 0.7405 - val_accuracy: 0.5599\n",
            "Epoch 258/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6272 - accuracy: 0.6158 - val_loss: 0.7708 - val_accuracy: 0.5630\n",
            "Epoch 259/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6231 - accuracy: 0.6180 - val_loss: 0.7615 - val_accuracy: 0.5622\n",
            "Epoch 260/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6187 - accuracy: 0.6204 - val_loss: 0.7483 - val_accuracy: 0.5603\n",
            "Epoch 261/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.6187 - val_loss: 0.7555 - val_accuracy: 0.5622\n",
            "Epoch 262/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6161 - val_loss: 0.7703 - val_accuracy: 0.5614\n",
            "Epoch 263/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6190 - val_loss: 0.7705 - val_accuracy: 0.5626\n",
            "Epoch 264/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6173 - accuracy: 0.6181 - val_loss: 0.7678 - val_accuracy: 0.5626\n",
            "Epoch 265/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6184 - val_loss: 0.7473 - val_accuracy: 0.5637\n",
            "Epoch 266/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6160 - val_loss: 0.7777 - val_accuracy: 0.5630\n",
            "Epoch 267/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6191 - val_loss: 0.7777 - val_accuracy: 0.5637\n",
            "Epoch 268/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6231 - accuracy: 0.6200 - val_loss: 0.7560 - val_accuracy: 0.5626\n",
            "Epoch 269/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.6199 - val_loss: 0.7605 - val_accuracy: 0.5618\n",
            "Epoch 270/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.6204 - val_loss: 0.7724 - val_accuracy: 0.5622\n",
            "Epoch 271/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6191 - val_loss: 0.7770 - val_accuracy: 0.5622\n",
            "Epoch 272/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6206 - val_loss: 0.7681 - val_accuracy: 0.5633\n",
            "Epoch 273/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6276 - accuracy: 0.6173 - val_loss: 0.7687 - val_accuracy: 0.5610\n",
            "Epoch 274/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6332 - accuracy: 0.6148 - val_loss: 0.7572 - val_accuracy: 0.5626\n",
            "Epoch 275/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6329 - accuracy: 0.6196 - val_loss: 0.8074 - val_accuracy: 0.5622\n",
            "Epoch 276/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6263 - accuracy: 0.6182 - val_loss: 0.7752 - val_accuracy: 0.5630\n",
            "Epoch 277/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6250 - accuracy: 0.6162 - val_loss: 0.7764 - val_accuracy: 0.5675\n",
            "Epoch 278/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6187 - val_loss: 0.7790 - val_accuracy: 0.5610\n",
            "Epoch 279/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.6192 - val_loss: 0.7422 - val_accuracy: 0.5626\n",
            "Epoch 280/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6187 - val_loss: 0.7589 - val_accuracy: 0.5717\n",
            "Epoch 281/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.6180 - val_loss: 0.7602 - val_accuracy: 0.5725\n",
            "Epoch 282/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.6177 - val_loss: 0.7582 - val_accuracy: 0.5675\n",
            "Epoch 283/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.6167 - val_loss: 0.7655 - val_accuracy: 0.5671\n",
            "Epoch 284/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6235 - accuracy: 0.6191 - val_loss: 0.7749 - val_accuracy: 0.5675\n",
            "Epoch 285/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6206 - accuracy: 0.6167 - val_loss: 0.7928 - val_accuracy: 0.5675\n",
            "Epoch 286/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6179 - val_loss: 0.7456 - val_accuracy: 0.5683\n",
            "Epoch 287/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6184 - val_loss: 0.7622 - val_accuracy: 0.5630\n",
            "Epoch 288/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6252 - accuracy: 0.6151 - val_loss: 0.7519 - val_accuracy: 0.5641\n",
            "Epoch 289/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.6172 - val_loss: 0.7769 - val_accuracy: 0.5713\n",
            "Epoch 290/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.6200 - val_loss: 0.7666 - val_accuracy: 0.5668\n",
            "Epoch 291/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.6195 - val_loss: 0.7865 - val_accuracy: 0.5633\n",
            "Epoch 292/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6216 - accuracy: 0.6137 - val_loss: 0.7787 - val_accuracy: 0.5599\n",
            "Epoch 293/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.6170 - val_loss: 0.7808 - val_accuracy: 0.5652\n",
            "Epoch 294/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6172 - val_loss: 0.7983 - val_accuracy: 0.5668\n",
            "Epoch 295/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6208 - accuracy: 0.6195 - val_loss: 0.7730 - val_accuracy: 0.5671\n",
            "Epoch 296/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6378 - accuracy: 0.6184 - val_loss: 0.7401 - val_accuracy: 0.5671\n",
            "Epoch 297/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6332 - accuracy: 0.6190 - val_loss: 0.7767 - val_accuracy: 0.5668\n",
            "Epoch 298/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6270 - accuracy: 0.6206 - val_loss: 0.7744 - val_accuracy: 0.5645\n",
            "Epoch 299/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6232 - accuracy: 0.6165 - val_loss: 0.7704 - val_accuracy: 0.5649\n",
            "Epoch 300/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6173 - val_loss: 0.7718 - val_accuracy: 0.5702\n",
            "Epoch 301/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6174 - accuracy: 0.6187 - val_loss: 0.7793 - val_accuracy: 0.5683\n",
            "Epoch 302/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6200 - val_loss: 0.7831 - val_accuracy: 0.5679\n",
            "Epoch 303/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6204 - val_loss: 0.7475 - val_accuracy: 0.5671\n",
            "Epoch 304/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.6192 - val_loss: 0.7714 - val_accuracy: 0.5721\n",
            "Epoch 305/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.6121 - val_loss: 0.7558 - val_accuracy: 0.5687\n",
            "Epoch 306/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6300 - accuracy: 0.6138 - val_loss: 0.7513 - val_accuracy: 0.5633\n",
            "Epoch 307/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6114 - val_loss: 0.7743 - val_accuracy: 0.5599\n",
            "Epoch 308/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.6172 - val_loss: 0.7700 - val_accuracy: 0.5637\n",
            "Epoch 309/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6201 - accuracy: 0.6146 - val_loss: 0.7371 - val_accuracy: 0.5725\n",
            "Epoch 310/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6157 - val_loss: 0.7562 - val_accuracy: 0.5721\n",
            "Epoch 311/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6193 - accuracy: 0.6195 - val_loss: 0.7574 - val_accuracy: 0.5610\n",
            "Epoch 312/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6186 - accuracy: 0.6180 - val_loss: 0.7537 - val_accuracy: 0.5610\n",
            "Epoch 313/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6149 - val_loss: 0.7596 - val_accuracy: 0.5630\n",
            "Epoch 314/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.6151 - val_loss: 0.7667 - val_accuracy: 0.5630\n",
            "Epoch 315/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.6100 - val_loss: 0.7527 - val_accuracy: 0.5618\n",
            "Epoch 316/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6274 - accuracy: 0.6128 - val_loss: 0.7602 - val_accuracy: 0.5626\n",
            "Epoch 317/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6158 - val_loss: 0.7630 - val_accuracy: 0.5649\n",
            "Epoch 318/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6208 - accuracy: 0.6195 - val_loss: 0.7532 - val_accuracy: 0.5626\n",
            "Epoch 319/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6184 - val_loss: 0.7722 - val_accuracy: 0.5637\n",
            "Epoch 320/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6179 - val_loss: 0.7916 - val_accuracy: 0.5595\n",
            "Epoch 321/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6312 - accuracy: 0.6153 - val_loss: 0.7645 - val_accuracy: 0.5610\n",
            "Epoch 322/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6179 - val_loss: 0.7670 - val_accuracy: 0.5641\n",
            "Epoch 323/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6182 - val_loss: 0.7677 - val_accuracy: 0.5637\n",
            "Epoch 324/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6162 - val_loss: 0.7871 - val_accuracy: 0.5649\n",
            "Epoch 325/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6200 - val_loss: 0.7909 - val_accuracy: 0.5645\n",
            "Epoch 326/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.6195 - val_loss: 0.7905 - val_accuracy: 0.5675\n",
            "Epoch 327/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6349 - accuracy: 0.6176 - val_loss: 0.7508 - val_accuracy: 0.5671\n",
            "Epoch 328/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.6187 - val_loss: 0.7395 - val_accuracy: 0.5626\n",
            "Epoch 329/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6225 - accuracy: 0.6194 - val_loss: 0.7528 - val_accuracy: 0.5626\n",
            "Epoch 330/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6233 - accuracy: 0.6182 - val_loss: 0.7339 - val_accuracy: 0.5618\n",
            "Epoch 331/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.6184 - val_loss: 0.7396 - val_accuracy: 0.5660\n",
            "Epoch 332/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.6199 - val_loss: 0.7516 - val_accuracy: 0.5626\n",
            "Epoch 333/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6259 - accuracy: 0.6195 - val_loss: 0.7563 - val_accuracy: 0.5702\n",
            "Epoch 334/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6157 - val_loss: 0.7445 - val_accuracy: 0.5660\n",
            "Epoch 335/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6181 - val_loss: 0.7609 - val_accuracy: 0.5664\n",
            "Epoch 336/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6189 - val_loss: 0.7430 - val_accuracy: 0.5660\n",
            "Epoch 337/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.6184 - val_loss: 0.7529 - val_accuracy: 0.5664\n",
            "Epoch 338/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6209 - accuracy: 0.6149 - val_loss: 0.7544 - val_accuracy: 0.5671\n",
            "Epoch 339/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6236 - accuracy: 0.6181 - val_loss: 0.7643 - val_accuracy: 0.5713\n",
            "Epoch 340/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.6154 - val_loss: 0.7358 - val_accuracy: 0.5709\n",
            "Epoch 341/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6304 - accuracy: 0.6184 - val_loss: 0.7429 - val_accuracy: 0.5706\n",
            "Epoch 342/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.6161 - val_loss: 0.7504 - val_accuracy: 0.5626\n",
            "Epoch 343/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.6168 - val_loss: 0.7558 - val_accuracy: 0.5675\n",
            "Epoch 344/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6209 - accuracy: 0.6192 - val_loss: 0.7618 - val_accuracy: 0.5763\n",
            "Epoch 345/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6252 - accuracy: 0.6168 - val_loss: 0.7827 - val_accuracy: 0.5637\n",
            "Epoch 346/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6261 - accuracy: 0.6163 - val_loss: 0.7517 - val_accuracy: 0.5622\n",
            "Epoch 347/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6254 - accuracy: 0.6200 - val_loss: 0.7368 - val_accuracy: 0.5618\n",
            "Epoch 348/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6204 - val_loss: 0.7464 - val_accuracy: 0.5660\n",
            "Epoch 349/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6165 - accuracy: 0.6208 - val_loss: 0.7497 - val_accuracy: 0.5633\n",
            "Epoch 350/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6186 - val_loss: 0.7556 - val_accuracy: 0.5610\n",
            "Epoch 351/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6180 - val_loss: 0.7507 - val_accuracy: 0.5607\n",
            "Epoch 352/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6238 - accuracy: 0.6172 - val_loss: 0.7614 - val_accuracy: 0.5622\n",
            "Epoch 353/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6194 - val_loss: 0.7450 - val_accuracy: 0.5660\n",
            "Epoch 354/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6175 - val_loss: 0.7658 - val_accuracy: 0.5656\n",
            "Epoch 355/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.6210 - val_loss: 0.7620 - val_accuracy: 0.5660\n",
            "Epoch 356/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6244 - accuracy: 0.6211 - val_loss: 0.7769 - val_accuracy: 0.5675\n",
            "Epoch 357/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6259 - accuracy: 0.6189 - val_loss: 0.7677 - val_accuracy: 0.5641\n",
            "Epoch 358/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6244 - accuracy: 0.6182 - val_loss: 0.7800 - val_accuracy: 0.5671\n",
            "Epoch 359/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6204 - accuracy: 0.6182 - val_loss: 0.7801 - val_accuracy: 0.5637\n",
            "Epoch 360/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6194 - accuracy: 0.6165 - val_loss: 0.7807 - val_accuracy: 0.5660\n",
            "Epoch 361/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.6199 - val_loss: 0.7774 - val_accuracy: 0.5664\n",
            "Epoch 362/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6205 - val_loss: 0.7970 - val_accuracy: 0.5660\n",
            "Epoch 363/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6251 - accuracy: 0.6195 - val_loss: 0.7923 - val_accuracy: 0.5664\n",
            "Epoch 364/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6177 - val_loss: 0.7843 - val_accuracy: 0.5660\n",
            "Epoch 365/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6197 - accuracy: 0.6214 - val_loss: 0.7944 - val_accuracy: 0.5656\n",
            "Epoch 366/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.6181 - val_loss: 0.7994 - val_accuracy: 0.5664\n",
            "Epoch 367/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6238 - accuracy: 0.6203 - val_loss: 0.7772 - val_accuracy: 0.5668\n",
            "Epoch 368/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6201 - val_loss: 0.7729 - val_accuracy: 0.5664\n",
            "Epoch 369/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6257 - accuracy: 0.6171 - val_loss: 0.7819 - val_accuracy: 0.5618\n",
            "Epoch 370/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6222 - accuracy: 0.6192 - val_loss: 0.7727 - val_accuracy: 0.5645\n",
            "Epoch 371/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6245 - accuracy: 0.6201 - val_loss: 0.7976 - val_accuracy: 0.5660\n",
            "Epoch 372/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6256 - accuracy: 0.6199 - val_loss: 0.7619 - val_accuracy: 0.5649\n",
            "Epoch 373/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.6196 - val_loss: 0.7790 - val_accuracy: 0.5698\n",
            "Epoch 374/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6191 - accuracy: 0.6206 - val_loss: 0.7674 - val_accuracy: 0.5709\n",
            "Epoch 375/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6194 - val_loss: 0.7748 - val_accuracy: 0.5709\n",
            "Epoch 376/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.6225 - val_loss: 0.7816 - val_accuracy: 0.5664\n",
            "Epoch 377/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6155 - accuracy: 0.6196 - val_loss: 0.7939 - val_accuracy: 0.5626\n",
            "Epoch 378/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6171 - accuracy: 0.6166 - val_loss: 0.7829 - val_accuracy: 0.5713\n",
            "Epoch 379/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6204 - accuracy: 0.6192 - val_loss: 0.7732 - val_accuracy: 0.5687\n",
            "Epoch 380/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6238 - accuracy: 0.6151 - val_loss: 0.7810 - val_accuracy: 0.5713\n",
            "Epoch 381/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.6189 - val_loss: 0.7744 - val_accuracy: 0.5713\n",
            "Epoch 382/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6243 - accuracy: 0.6166 - val_loss: 0.7617 - val_accuracy: 0.5656\n",
            "Epoch 383/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6186 - accuracy: 0.6170 - val_loss: 0.7668 - val_accuracy: 0.5717\n",
            "Epoch 384/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6166 - accuracy: 0.6201 - val_loss: 0.7635 - val_accuracy: 0.5671\n",
            "Epoch 385/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.6167 - val_loss: 0.7601 - val_accuracy: 0.5671\n",
            "Epoch 386/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6229 - accuracy: 0.6168 - val_loss: 0.7481 - val_accuracy: 0.5656\n",
            "Epoch 387/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6312 - accuracy: 0.6173 - val_loss: 0.7690 - val_accuracy: 0.5649\n",
            "Epoch 388/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6312 - accuracy: 0.6177 - val_loss: 0.7626 - val_accuracy: 0.5668\n",
            "Epoch 389/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6187 - val_loss: 0.7574 - val_accuracy: 0.5637\n",
            "Epoch 390/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6194 - val_loss: 0.7409 - val_accuracy: 0.5641\n",
            "Epoch 391/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6236 - accuracy: 0.6173 - val_loss: 0.7478 - val_accuracy: 0.5736\n",
            "Epoch 392/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6250 - accuracy: 0.6176 - val_loss: 0.7716 - val_accuracy: 0.5668\n",
            "Epoch 393/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6211 - val_loss: 0.7633 - val_accuracy: 0.5641\n",
            "Epoch 394/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.6201 - val_loss: 0.7752 - val_accuracy: 0.5660\n",
            "Epoch 395/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.6234 - val_loss: 0.7710 - val_accuracy: 0.5675\n",
            "Epoch 396/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6131 - accuracy: 0.6210 - val_loss: 0.7758 - val_accuracy: 0.5668\n",
            "Epoch 397/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6145 - accuracy: 0.6224 - val_loss: 0.7856 - val_accuracy: 0.5675\n",
            "Epoch 398/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6231 - accuracy: 0.6160 - val_loss: 0.7752 - val_accuracy: 0.5675\n",
            "Epoch 399/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.6175 - val_loss: 0.7969 - val_accuracy: 0.5622\n",
            "Epoch 400/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.6177 - val_loss: 0.7736 - val_accuracy: 0.5618\n",
            "Epoch 401/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6248 - accuracy: 0.6184 - val_loss: 0.7898 - val_accuracy: 0.5614\n",
            "Epoch 402/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6257 - accuracy: 0.6192 - val_loss: 0.7497 - val_accuracy: 0.5630\n",
            "Epoch 403/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.6196 - val_loss: 0.7454 - val_accuracy: 0.5675\n",
            "Epoch 404/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6190 - accuracy: 0.6206 - val_loss: 0.7586 - val_accuracy: 0.5630\n",
            "Epoch 405/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.6201 - val_loss: 0.7525 - val_accuracy: 0.5626\n",
            "Epoch 406/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6166 - accuracy: 0.6198 - val_loss: 0.7646 - val_accuracy: 0.5671\n",
            "Epoch 407/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.6218 - val_loss: 0.7647 - val_accuracy: 0.5630\n",
            "Epoch 408/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6182 - val_loss: 0.7586 - val_accuracy: 0.5664\n",
            "Epoch 409/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6209 - val_loss: 0.7789 - val_accuracy: 0.5660\n",
            "Epoch 410/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.6211 - val_loss: 0.7531 - val_accuracy: 0.5668\n",
            "Epoch 411/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6304 - accuracy: 0.6187 - val_loss: 0.7909 - val_accuracy: 0.5630\n",
            "Epoch 412/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6293 - accuracy: 0.6157 - val_loss: 0.7441 - val_accuracy: 0.5675\n",
            "Epoch 413/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.6177 - val_loss: 0.7543 - val_accuracy: 0.5668\n",
            "Epoch 414/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6196 - val_loss: 0.7607 - val_accuracy: 0.5630\n",
            "Epoch 415/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.6208 - val_loss: 0.7681 - val_accuracy: 0.5645\n",
            "Epoch 416/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6138 - accuracy: 0.6208 - val_loss: 0.7545 - val_accuracy: 0.5671\n",
            "Epoch 417/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6128 - accuracy: 0.6223 - val_loss: 0.7618 - val_accuracy: 0.5668\n",
            "Epoch 418/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.6214 - val_loss: 0.7592 - val_accuracy: 0.5675\n",
            "Epoch 419/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.6210 - val_loss: 0.7356 - val_accuracy: 0.5660\n",
            "Epoch 420/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6313 - accuracy: 0.6171 - val_loss: 0.7679 - val_accuracy: 0.5649\n",
            "Epoch 421/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6192 - val_loss: 0.7659 - val_accuracy: 0.5645\n",
            "Epoch 422/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.6203 - val_loss: 0.7734 - val_accuracy: 0.5649\n",
            "Epoch 423/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6204 - val_loss: 0.7781 - val_accuracy: 0.5690\n",
            "Epoch 424/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.6181 - val_loss: 0.7676 - val_accuracy: 0.5702\n",
            "Epoch 425/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6368 - accuracy: 0.6171 - val_loss: 0.8099 - val_accuracy: 0.5637\n",
            "Epoch 426/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6312 - accuracy: 0.6173 - val_loss: 0.7753 - val_accuracy: 0.5698\n",
            "Epoch 427/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6248 - accuracy: 0.6201 - val_loss: 0.7476 - val_accuracy: 0.5649\n",
            "Epoch 428/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.6206 - val_loss: 0.7620 - val_accuracy: 0.5618\n",
            "Epoch 429/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6190 - val_loss: 0.7476 - val_accuracy: 0.5675\n",
            "Epoch 430/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.6215 - val_loss: 0.7638 - val_accuracy: 0.5630\n",
            "Epoch 431/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6213 - val_loss: 0.7584 - val_accuracy: 0.5649\n",
            "Epoch 432/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6134 - accuracy: 0.6204 - val_loss: 0.7451 - val_accuracy: 0.5630\n",
            "Epoch 433/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.6187 - val_loss: 0.7612 - val_accuracy: 0.5649\n",
            "Epoch 434/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6138 - accuracy: 0.6192 - val_loss: 0.7689 - val_accuracy: 0.5671\n",
            "Epoch 435/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6140 - accuracy: 0.6211 - val_loss: 0.7653 - val_accuracy: 0.5675\n",
            "Epoch 436/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6213 - val_loss: 0.7717 - val_accuracy: 0.5664\n",
            "Epoch 437/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6159 - accuracy: 0.6194 - val_loss: 0.7750 - val_accuracy: 0.5622\n",
            "Epoch 438/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.6201 - val_loss: 0.7762 - val_accuracy: 0.5626\n",
            "Epoch 439/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6177 - val_loss: 0.7582 - val_accuracy: 0.5614\n",
            "Epoch 440/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.6157 - val_loss: 0.7618 - val_accuracy: 0.5656\n",
            "Epoch 441/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6364 - accuracy: 0.6165 - val_loss: 0.7397 - val_accuracy: 0.5660\n",
            "Epoch 442/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6285 - accuracy: 0.6115 - val_loss: 0.7738 - val_accuracy: 0.5641\n",
            "Epoch 443/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6252 - accuracy: 0.6181 - val_loss: 0.7441 - val_accuracy: 0.5664\n",
            "Epoch 444/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6208 - accuracy: 0.6175 - val_loss: 0.7561 - val_accuracy: 0.5664\n",
            "Epoch 445/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.6217 - val_loss: 0.7525 - val_accuracy: 0.5664\n",
            "Epoch 446/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6165 - accuracy: 0.6187 - val_loss: 0.7767 - val_accuracy: 0.5622\n",
            "Epoch 447/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6211 - val_loss: 0.7636 - val_accuracy: 0.5595\n",
            "Epoch 448/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6187 - accuracy: 0.6198 - val_loss: 0.7692 - val_accuracy: 0.5618\n",
            "Epoch 449/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6171 - accuracy: 0.6199 - val_loss: 0.7703 - val_accuracy: 0.5618\n",
            "Epoch 450/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6198 - val_loss: 0.7680 - val_accuracy: 0.5664\n",
            "Epoch 451/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6215 - val_loss: 0.7552 - val_accuracy: 0.5694\n",
            "Epoch 452/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6174 - accuracy: 0.6189 - val_loss: 0.7874 - val_accuracy: 0.5660\n",
            "Epoch 453/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6166 - accuracy: 0.6186 - val_loss: 0.7917 - val_accuracy: 0.5668\n",
            "Epoch 454/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6135 - accuracy: 0.6210 - val_loss: 0.7774 - val_accuracy: 0.5668\n",
            "Epoch 455/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6208 - val_loss: 0.7743 - val_accuracy: 0.5652\n",
            "Epoch 456/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.6138 - val_loss: 0.7923 - val_accuracy: 0.5641\n",
            "Epoch 457/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.6175 - val_loss: 0.7317 - val_accuracy: 0.5687\n",
            "Epoch 458/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6290 - accuracy: 0.6146 - val_loss: 0.7687 - val_accuracy: 0.5671\n",
            "Epoch 459/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.6149 - val_loss: 0.7637 - val_accuracy: 0.5683\n",
            "Epoch 460/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6179 - val_loss: 0.7582 - val_accuracy: 0.5671\n",
            "Epoch 461/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.6195 - val_loss: 0.7578 - val_accuracy: 0.5736\n",
            "Epoch 462/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6192 - val_loss: 0.7772 - val_accuracy: 0.5728\n",
            "Epoch 463/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6163 - val_loss: 0.7536 - val_accuracy: 0.5732\n",
            "Epoch 464/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.6177 - val_loss: 0.7889 - val_accuracy: 0.5725\n",
            "Epoch 465/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.6158 - val_loss: 0.7673 - val_accuracy: 0.5732\n",
            "Epoch 466/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6155 - accuracy: 0.6209 - val_loss: 0.7635 - val_accuracy: 0.5508\n",
            "Epoch 467/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.6176 - val_loss: 0.7727 - val_accuracy: 0.5668\n",
            "Epoch 468/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6173 - accuracy: 0.6195 - val_loss: 0.7833 - val_accuracy: 0.5645\n",
            "Epoch 469/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6217 - val_loss: 0.7513 - val_accuracy: 0.5652\n",
            "Epoch 470/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6191 - val_loss: 0.7521 - val_accuracy: 0.5698\n",
            "Epoch 471/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6235 - accuracy: 0.6165 - val_loss: 0.7699 - val_accuracy: 0.5706\n",
            "Epoch 472/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.6180 - val_loss: 0.7759 - val_accuracy: 0.5668\n",
            "Epoch 473/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6236 - accuracy: 0.6165 - val_loss: 0.7655 - val_accuracy: 0.5630\n",
            "Epoch 474/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6218 - accuracy: 0.6173 - val_loss: 0.7769 - val_accuracy: 0.5630\n",
            "Epoch 475/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6203 - val_loss: 0.7739 - val_accuracy: 0.5633\n",
            "Epoch 476/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6186 - val_loss: 0.7902 - val_accuracy: 0.5683\n",
            "Epoch 477/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6318 - accuracy: 0.6204 - val_loss: 0.7907 - val_accuracy: 0.5679\n",
            "Epoch 478/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6350 - accuracy: 0.6182 - val_loss: 0.7748 - val_accuracy: 0.5671\n",
            "Epoch 479/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6240 - accuracy: 0.6200 - val_loss: 0.7791 - val_accuracy: 0.5675\n",
            "Epoch 480/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6177 - val_loss: 0.7871 - val_accuracy: 0.5713\n",
            "Epoch 481/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.6201 - val_loss: 0.7815 - val_accuracy: 0.5728\n",
            "Epoch 482/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6167 - val_loss: 0.7824 - val_accuracy: 0.5709\n",
            "Epoch 483/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6157 - val_loss: 0.7737 - val_accuracy: 0.5713\n",
            "Epoch 484/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.6184 - val_loss: 0.7754 - val_accuracy: 0.5599\n",
            "Epoch 485/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6191 - accuracy: 0.6203 - val_loss: 0.7820 - val_accuracy: 0.5599\n",
            "Epoch 486/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6174 - accuracy: 0.6200 - val_loss: 0.7858 - val_accuracy: 0.5690\n",
            "Epoch 487/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6277 - accuracy: 0.6165 - val_loss: 0.8048 - val_accuracy: 0.5610\n",
            "Epoch 488/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6308 - accuracy: 0.6147 - val_loss: 0.7612 - val_accuracy: 0.5626\n",
            "Epoch 489/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6186 - val_loss: 0.7582 - val_accuracy: 0.5622\n",
            "Epoch 490/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6215 - accuracy: 0.6198 - val_loss: 0.7468 - val_accuracy: 0.5630\n",
            "Epoch 491/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6208 - val_loss: 0.7573 - val_accuracy: 0.5656\n",
            "Epoch 492/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6190 - val_loss: 0.7451 - val_accuracy: 0.5679\n",
            "Epoch 493/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.6116 - val_loss: 0.7641 - val_accuracy: 0.5652\n",
            "Epoch 494/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6254 - accuracy: 0.6167 - val_loss: 0.7715 - val_accuracy: 0.5649\n",
            "Epoch 495/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6179 - accuracy: 0.6203 - val_loss: 0.7894 - val_accuracy: 0.5671\n",
            "Epoch 496/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6150 - accuracy: 0.6204 - val_loss: 0.8008 - val_accuracy: 0.5633\n",
            "Epoch 497/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6127 - accuracy: 0.6191 - val_loss: 0.8143 - val_accuracy: 0.5633\n",
            "Epoch 498/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6157 - accuracy: 0.6209 - val_loss: 0.7562 - val_accuracy: 0.5641\n",
            "Epoch 499/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6236 - accuracy: 0.6196 - val_loss: 0.7591 - val_accuracy: 0.5675\n",
            "Epoch 500/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6276 - accuracy: 0.6176 - val_loss: 0.7936 - val_accuracy: 0.5683\n",
            "Epoch 501/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6248 - accuracy: 0.6213 - val_loss: 0.7897 - val_accuracy: 0.5622\n",
            "Epoch 502/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6244 - accuracy: 0.6204 - val_loss: 0.7739 - val_accuracy: 0.5633\n",
            "Epoch 503/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6266 - accuracy: 0.6157 - val_loss: 0.7787 - val_accuracy: 0.5668\n",
            "Epoch 504/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6198 - val_loss: 0.7766 - val_accuracy: 0.5660\n",
            "Epoch 505/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6235 - accuracy: 0.6199 - val_loss: 0.8034 - val_accuracy: 0.5660\n",
            "Epoch 506/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6187 - accuracy: 0.6219 - val_loss: 0.7999 - val_accuracy: 0.5664\n",
            "Epoch 507/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6222 - val_loss: 0.8013 - val_accuracy: 0.5664\n",
            "Epoch 508/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6141 - accuracy: 0.6217 - val_loss: 0.7917 - val_accuracy: 0.5668\n",
            "Epoch 509/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.6176 - val_loss: 0.7843 - val_accuracy: 0.5660\n",
            "Epoch 510/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6194 - accuracy: 0.6173 - val_loss: 0.7218 - val_accuracy: 0.5637\n",
            "Epoch 511/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6370 - accuracy: 0.6163 - val_loss: 0.7652 - val_accuracy: 0.5671\n",
            "Epoch 512/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6483 - accuracy: 0.6143 - val_loss: 0.7698 - val_accuracy: 0.5656\n",
            "Epoch 513/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6356 - accuracy: 0.6199 - val_loss: 0.7606 - val_accuracy: 0.5671\n",
            "Epoch 514/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6288 - accuracy: 0.6204 - val_loss: 0.7605 - val_accuracy: 0.5664\n",
            "Epoch 515/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6238 - accuracy: 0.6211 - val_loss: 0.7727 - val_accuracy: 0.5595\n",
            "Epoch 516/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6182 - val_loss: 0.7710 - val_accuracy: 0.5633\n",
            "Epoch 517/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6204 - accuracy: 0.6176 - val_loss: 0.7589 - val_accuracy: 0.5694\n",
            "Epoch 518/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6201 - val_loss: 0.7582 - val_accuracy: 0.5713\n",
            "Epoch 519/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6166 - val_loss: 0.7727 - val_accuracy: 0.5641\n",
            "Epoch 520/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6175 - val_loss: 0.7419 - val_accuracy: 0.5633\n",
            "Epoch 521/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6189 - val_loss: 0.7561 - val_accuracy: 0.5671\n",
            "Epoch 522/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6194 - val_loss: 0.7378 - val_accuracy: 0.5633\n",
            "Epoch 523/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6201 - val_loss: 0.7220 - val_accuracy: 0.5679\n",
            "Epoch 524/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6263 - accuracy: 0.6130 - val_loss: 0.7353 - val_accuracy: 0.5679\n",
            "Epoch 525/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6196 - val_loss: 0.7573 - val_accuracy: 0.5679\n",
            "Epoch 526/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.6139 - val_loss: 0.7211 - val_accuracy: 0.5690\n",
            "Epoch 527/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6190 - val_loss: 0.7454 - val_accuracy: 0.5687\n",
            "Epoch 528/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6219 - val_loss: 0.7509 - val_accuracy: 0.5675\n",
            "Epoch 529/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.6156 - val_loss: 0.7442 - val_accuracy: 0.5652\n",
            "Epoch 530/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6166 - val_loss: 0.7666 - val_accuracy: 0.5683\n",
            "Epoch 531/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6175 - val_loss: 0.7618 - val_accuracy: 0.5694\n",
            "Epoch 532/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.6175 - val_loss: 0.7473 - val_accuracy: 0.5690\n",
            "Epoch 533/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.6201 - val_loss: 0.7742 - val_accuracy: 0.5675\n",
            "Epoch 534/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6148 - val_loss: 0.7676 - val_accuracy: 0.5683\n",
            "Epoch 535/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6323 - accuracy: 0.6163 - val_loss: 0.7350 - val_accuracy: 0.5645\n",
            "Epoch 536/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6420 - accuracy: 0.6158 - val_loss: 0.7346 - val_accuracy: 0.5698\n",
            "Epoch 537/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6325 - accuracy: 0.6172 - val_loss: 0.7598 - val_accuracy: 0.5668\n",
            "Epoch 538/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6266 - accuracy: 0.6172 - val_loss: 0.7296 - val_accuracy: 0.5671\n",
            "Epoch 539/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6220 - val_loss: 0.7406 - val_accuracy: 0.5732\n",
            "Epoch 540/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6190 - accuracy: 0.6190 - val_loss: 0.7468 - val_accuracy: 0.5736\n",
            "Epoch 541/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.6190 - val_loss: 0.7444 - val_accuracy: 0.5728\n",
            "Epoch 542/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6142 - accuracy: 0.6196 - val_loss: 0.7629 - val_accuracy: 0.5668\n",
            "Epoch 543/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.6200 - val_loss: 0.7509 - val_accuracy: 0.5656\n",
            "Epoch 544/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6144 - accuracy: 0.6210 - val_loss: 0.7670 - val_accuracy: 0.5702\n",
            "Epoch 545/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6140 - accuracy: 0.6194 - val_loss: 0.7527 - val_accuracy: 0.5706\n",
            "Epoch 546/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6194 - val_loss: 0.7463 - val_accuracy: 0.5633\n",
            "Epoch 547/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6177 - val_loss: 0.7477 - val_accuracy: 0.5713\n",
            "Epoch 548/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6235 - accuracy: 0.6182 - val_loss: 0.7592 - val_accuracy: 0.5671\n",
            "Epoch 549/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6171 - accuracy: 0.6213 - val_loss: 0.7685 - val_accuracy: 0.5664\n",
            "Epoch 550/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6178 - accuracy: 0.6225 - val_loss: 0.7642 - val_accuracy: 0.5732\n",
            "Epoch 551/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6209 - val_loss: 0.7554 - val_accuracy: 0.5664\n",
            "Epoch 552/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6208 - val_loss: 0.7537 - val_accuracy: 0.5671\n",
            "Epoch 553/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6159 - accuracy: 0.6210 - val_loss: 0.7551 - val_accuracy: 0.5675\n",
            "Epoch 554/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6146 - accuracy: 0.6218 - val_loss: 0.7777 - val_accuracy: 0.5668\n",
            "Epoch 555/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6199 - val_loss: 0.7396 - val_accuracy: 0.5679\n",
            "Epoch 556/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6190 - accuracy: 0.6206 - val_loss: 0.7554 - val_accuracy: 0.5649\n",
            "Epoch 557/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.6132 - val_loss: 0.7324 - val_accuracy: 0.5736\n",
            "Epoch 558/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6290 - accuracy: 0.6192 - val_loss: 0.7507 - val_accuracy: 0.5671\n",
            "Epoch 559/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6187 - val_loss: 0.7753 - val_accuracy: 0.5641\n",
            "Epoch 560/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6172 - val_loss: 0.7598 - val_accuracy: 0.5633\n",
            "Epoch 561/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6194 - accuracy: 0.6175 - val_loss: 0.7550 - val_accuracy: 0.5637\n",
            "Epoch 562/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6220 - val_loss: 0.7493 - val_accuracy: 0.5645\n",
            "Epoch 563/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6146 - accuracy: 0.6194 - val_loss: 0.7591 - val_accuracy: 0.5637\n",
            "Epoch 564/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6128 - accuracy: 0.6189 - val_loss: 0.7828 - val_accuracy: 0.5671\n",
            "Epoch 565/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.6195 - val_loss: 0.7766 - val_accuracy: 0.5683\n",
            "Epoch 566/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6276 - accuracy: 0.6180 - val_loss: 0.7759 - val_accuracy: 0.5740\n",
            "Epoch 567/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6218 - accuracy: 0.6157 - val_loss: 0.7478 - val_accuracy: 0.5671\n",
            "Epoch 568/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6217 - accuracy: 0.6195 - val_loss: 0.7676 - val_accuracy: 0.5706\n",
            "Epoch 569/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6162 - val_loss: 0.7488 - val_accuracy: 0.5683\n",
            "Epoch 570/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6258 - accuracy: 0.6134 - val_loss: 0.7535 - val_accuracy: 0.5630\n",
            "Epoch 571/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6261 - accuracy: 0.6175 - val_loss: 0.7622 - val_accuracy: 0.5656\n",
            "Epoch 572/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6308 - accuracy: 0.6172 - val_loss: 0.7609 - val_accuracy: 0.5683\n",
            "Epoch 573/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.6177 - val_loss: 0.7394 - val_accuracy: 0.5645\n",
            "Epoch 574/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6273 - accuracy: 0.6176 - val_loss: 0.7614 - val_accuracy: 0.5694\n",
            "Epoch 575/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6249 - accuracy: 0.6185 - val_loss: 0.7659 - val_accuracy: 0.5645\n",
            "Epoch 576/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6194 - accuracy: 0.6137 - val_loss: 0.7544 - val_accuracy: 0.5664\n",
            "Epoch 577/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6204 - accuracy: 0.6209 - val_loss: 0.7551 - val_accuracy: 0.5660\n",
            "Epoch 578/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6214 - val_loss: 0.7399 - val_accuracy: 0.5671\n",
            "Epoch 579/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.6187 - val_loss: 0.7709 - val_accuracy: 0.5637\n",
            "Epoch 580/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6227 - accuracy: 0.6154 - val_loss: 0.7712 - val_accuracy: 0.5645\n",
            "Epoch 581/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.6177 - val_loss: 0.7550 - val_accuracy: 0.5637\n",
            "Epoch 582/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6263 - accuracy: 0.6181 - val_loss: 0.7652 - val_accuracy: 0.5675\n",
            "Epoch 583/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6330 - accuracy: 0.6191 - val_loss: 0.7510 - val_accuracy: 0.5633\n",
            "Epoch 584/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6259 - accuracy: 0.6203 - val_loss: 0.7634 - val_accuracy: 0.5660\n",
            "Epoch 585/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6200 - val_loss: 0.7528 - val_accuracy: 0.5668\n",
            "Epoch 586/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6203 - val_loss: 0.7505 - val_accuracy: 0.5687\n",
            "Epoch 587/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6176 - accuracy: 0.6215 - val_loss: 0.7635 - val_accuracy: 0.5660\n",
            "Epoch 588/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6145 - accuracy: 0.6195 - val_loss: 0.7659 - val_accuracy: 0.5679\n",
            "Epoch 589/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.6189 - val_loss: 0.7791 - val_accuracy: 0.5717\n",
            "Epoch 590/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.6184 - val_loss: 0.7833 - val_accuracy: 0.5713\n",
            "Epoch 591/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6189 - val_loss: 0.8007 - val_accuracy: 0.5664\n",
            "Epoch 592/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.6224 - val_loss: 0.7730 - val_accuracy: 0.5641\n",
            "Epoch 593/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6231 - val_loss: 0.7858 - val_accuracy: 0.5664\n",
            "Epoch 594/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6208 - val_loss: 0.7585 - val_accuracy: 0.5668\n",
            "Epoch 595/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6224 - val_loss: 0.7573 - val_accuracy: 0.5633\n",
            "Epoch 596/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6294 - accuracy: 0.6190 - val_loss: 0.7683 - val_accuracy: 0.5630\n",
            "Epoch 597/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6278 - accuracy: 0.6181 - val_loss: 0.7820 - val_accuracy: 0.5630\n",
            "Epoch 598/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.6205 - val_loss: 0.7879 - val_accuracy: 0.5641\n",
            "Epoch 599/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.6190 - val_loss: 0.7744 - val_accuracy: 0.5588\n",
            "Epoch 600/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6250 - accuracy: 0.6171 - val_loss: 0.7758 - val_accuracy: 0.5603\n",
            "Epoch 601/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6225 - accuracy: 0.6184 - val_loss: 0.7911 - val_accuracy: 0.5633\n",
            "Epoch 602/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6204 - accuracy: 0.6186 - val_loss: 0.7670 - val_accuracy: 0.5599\n",
            "Epoch 603/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6190 - accuracy: 0.6140 - val_loss: 0.7834 - val_accuracy: 0.5664\n",
            "Epoch 604/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.6182 - val_loss: 0.7455 - val_accuracy: 0.5694\n",
            "Epoch 605/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6148 - val_loss: 0.7649 - val_accuracy: 0.5645\n",
            "Epoch 606/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6227 - accuracy: 0.6181 - val_loss: 0.7813 - val_accuracy: 0.5656\n",
            "Epoch 607/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.6154 - val_loss: 0.7809 - val_accuracy: 0.5630\n",
            "Epoch 608/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6181 - val_loss: 0.7708 - val_accuracy: 0.5630\n",
            "Epoch 609/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.6184 - val_loss: 0.7571 - val_accuracy: 0.5675\n",
            "Epoch 610/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.6203 - val_loss: 0.7645 - val_accuracy: 0.5622\n",
            "Epoch 611/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6190 - val_loss: 0.7365 - val_accuracy: 0.5603\n",
            "Epoch 612/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6217 - accuracy: 0.6177 - val_loss: 0.7712 - val_accuracy: 0.5637\n",
            "Epoch 613/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6296 - accuracy: 0.6167 - val_loss: 0.7683 - val_accuracy: 0.5660\n",
            "Epoch 614/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6180 - val_loss: 0.7628 - val_accuracy: 0.5641\n",
            "Epoch 615/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6184 - val_loss: 0.7695 - val_accuracy: 0.5656\n",
            "Epoch 616/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.6181 - val_loss: 0.7700 - val_accuracy: 0.5652\n",
            "Epoch 617/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6190 - val_loss: 0.7568 - val_accuracy: 0.5698\n",
            "Epoch 618/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6149 - val_loss: 0.7691 - val_accuracy: 0.5614\n",
            "Epoch 619/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6184 - val_loss: 0.7405 - val_accuracy: 0.5671\n",
            "Epoch 620/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6250 - accuracy: 0.6119 - val_loss: 0.7700 - val_accuracy: 0.5713\n",
            "Epoch 621/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.6171 - val_loss: 0.7678 - val_accuracy: 0.5630\n",
            "Epoch 622/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6163 - val_loss: 0.7456 - val_accuracy: 0.5717\n",
            "Epoch 623/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6189 - val_loss: 0.7585 - val_accuracy: 0.5656\n",
            "Epoch 624/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6201 - val_loss: 0.7728 - val_accuracy: 0.5668\n",
            "Epoch 625/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6204 - val_loss: 0.7726 - val_accuracy: 0.5690\n",
            "Epoch 626/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.6208 - val_loss: 0.7828 - val_accuracy: 0.5732\n",
            "Epoch 627/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.6189 - val_loss: 0.7597 - val_accuracy: 0.5728\n",
            "Epoch 628/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.6190 - val_loss: 0.7718 - val_accuracy: 0.5698\n",
            "Epoch 629/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6283 - accuracy: 0.6149 - val_loss: 0.7776 - val_accuracy: 0.5690\n",
            "Epoch 630/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.6142 - val_loss: 0.7748 - val_accuracy: 0.5675\n",
            "Epoch 631/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6179 - val_loss: 0.7721 - val_accuracy: 0.5717\n",
            "Epoch 632/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6181 - val_loss: 0.7803 - val_accuracy: 0.5664\n",
            "Epoch 633/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6190 - val_loss: 0.7602 - val_accuracy: 0.5698\n",
            "Epoch 634/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6268 - accuracy: 0.6140 - val_loss: 0.7735 - val_accuracy: 0.5717\n",
            "Epoch 635/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.6182 - val_loss: 0.7764 - val_accuracy: 0.5740\n",
            "Epoch 636/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6152 - accuracy: 0.6213 - val_loss: 0.7667 - val_accuracy: 0.5713\n",
            "Epoch 637/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6171 - accuracy: 0.6185 - val_loss: 0.8344 - val_accuracy: 0.5698\n",
            "Epoch 638/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6306 - accuracy: 0.6189 - val_loss: 0.7638 - val_accuracy: 0.5755\n",
            "Epoch 639/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6305 - accuracy: 0.6148 - val_loss: 0.7721 - val_accuracy: 0.5709\n",
            "Epoch 640/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6176 - val_loss: 0.7735 - val_accuracy: 0.5721\n",
            "Epoch 641/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.6203 - val_loss: 0.7692 - val_accuracy: 0.5679\n",
            "Epoch 642/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6189 - val_loss: 0.7645 - val_accuracy: 0.5679\n",
            "Epoch 643/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6156 - accuracy: 0.6173 - val_loss: 0.7867 - val_accuracy: 0.5683\n",
            "Epoch 644/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6176 - accuracy: 0.6172 - val_loss: 0.7762 - val_accuracy: 0.5671\n",
            "Epoch 645/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6180 - accuracy: 0.6184 - val_loss: 0.7640 - val_accuracy: 0.5633\n",
            "Epoch 646/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.6154 - val_loss: 0.7469 - val_accuracy: 0.5664\n",
            "Epoch 647/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6272 - accuracy: 0.6162 - val_loss: 0.7936 - val_accuracy: 0.5660\n",
            "Epoch 648/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6202 - accuracy: 0.6161 - val_loss: 0.7659 - val_accuracy: 0.5668\n",
            "Epoch 649/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6177 - accuracy: 0.6231 - val_loss: 0.7779 - val_accuracy: 0.5630\n",
            "Epoch 650/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6209 - val_loss: 0.7781 - val_accuracy: 0.5687\n",
            "Epoch 651/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6135 - accuracy: 0.6210 - val_loss: 0.7879 - val_accuracy: 0.5671\n",
            "Epoch 652/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6146 - accuracy: 0.6199 - val_loss: 0.7737 - val_accuracy: 0.5630\n",
            "Epoch 653/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6130 - accuracy: 0.6211 - val_loss: 0.7715 - val_accuracy: 0.5630\n",
            "Epoch 654/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6114 - accuracy: 0.6209 - val_loss: 0.7572 - val_accuracy: 0.5630\n",
            "Epoch 655/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.6228 - val_loss: 0.7698 - val_accuracy: 0.5660\n",
            "Epoch 656/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6194 - val_loss: 0.7624 - val_accuracy: 0.5683\n",
            "Epoch 657/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6211 - val_loss: 0.7648 - val_accuracy: 0.5683\n",
            "Epoch 658/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6217 - val_loss: 0.7588 - val_accuracy: 0.5721\n",
            "Epoch 659/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6229 - accuracy: 0.6204 - val_loss: 0.7543 - val_accuracy: 0.5713\n",
            "Epoch 660/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6327 - accuracy: 0.6182 - val_loss: 0.7906 - val_accuracy: 0.5656\n",
            "Epoch 661/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6229 - accuracy: 0.6194 - val_loss: 0.7846 - val_accuracy: 0.5717\n",
            "Epoch 662/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6189 - val_loss: 0.7531 - val_accuracy: 0.5660\n",
            "Epoch 663/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6185 - val_loss: 0.7746 - val_accuracy: 0.5713\n",
            "Epoch 664/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6322 - accuracy: 0.6173 - val_loss: 0.7553 - val_accuracy: 0.5721\n",
            "Epoch 665/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6261 - accuracy: 0.6177 - val_loss: 0.7673 - val_accuracy: 0.5744\n",
            "Epoch 666/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6187 - accuracy: 0.6204 - val_loss: 0.7736 - val_accuracy: 0.5721\n",
            "Epoch 667/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.6171 - val_loss: 0.7720 - val_accuracy: 0.5744\n",
            "Epoch 668/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6237 - val_loss: 0.7724 - val_accuracy: 0.5683\n",
            "Epoch 669/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6148 - accuracy: 0.6213 - val_loss: 0.7731 - val_accuracy: 0.5683\n",
            "Epoch 670/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.6206 - val_loss: 0.7875 - val_accuracy: 0.5747\n",
            "Epoch 671/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.6175 - val_loss: 0.7513 - val_accuracy: 0.5690\n",
            "Epoch 672/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6236 - accuracy: 0.6198 - val_loss: 0.7701 - val_accuracy: 0.5679\n",
            "Epoch 673/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6218 - val_loss: 0.7765 - val_accuracy: 0.5683\n",
            "Epoch 674/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6153 - accuracy: 0.6200 - val_loss: 0.7712 - val_accuracy: 0.5683\n",
            "Epoch 675/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.6194 - val_loss: 0.7639 - val_accuracy: 0.5747\n",
            "Epoch 676/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6139 - accuracy: 0.6192 - val_loss: 0.7673 - val_accuracy: 0.5744\n",
            "Epoch 677/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6161 - val_loss: 0.7678 - val_accuracy: 0.5633\n",
            "Epoch 678/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6189 - val_loss: 0.7287 - val_accuracy: 0.5683\n",
            "Epoch 679/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6259 - accuracy: 0.6165 - val_loss: 0.7632 - val_accuracy: 0.5664\n",
            "Epoch 680/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6176 - val_loss: 0.7407 - val_accuracy: 0.5721\n",
            "Epoch 681/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6191 - accuracy: 0.6185 - val_loss: 0.7590 - val_accuracy: 0.5622\n",
            "Epoch 682/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6171 - accuracy: 0.6187 - val_loss: 0.7604 - val_accuracy: 0.5660\n",
            "Epoch 683/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6273 - accuracy: 0.6147 - val_loss: 0.7708 - val_accuracy: 0.5687\n",
            "Epoch 684/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6294 - accuracy: 0.6175 - val_loss: 0.7828 - val_accuracy: 0.5687\n",
            "Epoch 685/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6249 - accuracy: 0.6186 - val_loss: 0.7814 - val_accuracy: 0.5645\n",
            "Epoch 686/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.6182 - val_loss: 0.7856 - val_accuracy: 0.5683\n",
            "Epoch 687/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.6186 - val_loss: 0.7892 - val_accuracy: 0.5690\n",
            "Epoch 688/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.6171 - val_loss: 0.7671 - val_accuracy: 0.5690\n",
            "Epoch 689/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.6157 - val_loss: 0.7812 - val_accuracy: 0.5690\n",
            "Epoch 690/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6128 - accuracy: 0.6177 - val_loss: 0.7924 - val_accuracy: 0.5641\n",
            "Epoch 691/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6126 - accuracy: 0.6180 - val_loss: 0.7819 - val_accuracy: 0.5683\n",
            "Epoch 692/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6119 - accuracy: 0.6199 - val_loss: 0.7624 - val_accuracy: 0.5721\n",
            "Epoch 693/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6152 - accuracy: 0.6194 - val_loss: 0.7955 - val_accuracy: 0.5717\n",
            "Epoch 694/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6273 - accuracy: 0.6127 - val_loss: 0.7771 - val_accuracy: 0.5664\n",
            "Epoch 695/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6291 - accuracy: 0.6156 - val_loss: 0.7517 - val_accuracy: 0.5713\n",
            "Epoch 696/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.6148 - val_loss: 0.7779 - val_accuracy: 0.5652\n",
            "Epoch 697/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6147 - val_loss: 0.7807 - val_accuracy: 0.5694\n",
            "Epoch 698/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6146 - accuracy: 0.6184 - val_loss: 0.7815 - val_accuracy: 0.5664\n",
            "Epoch 699/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6138 - val_loss: 0.7417 - val_accuracy: 0.5630\n",
            "Epoch 700/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.6175 - val_loss: 0.7699 - val_accuracy: 0.5633\n",
            "Epoch 701/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.6182 - val_loss: 0.7635 - val_accuracy: 0.5671\n",
            "Epoch 702/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6182 - val_loss: 0.7637 - val_accuracy: 0.5660\n",
            "Epoch 703/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6256 - accuracy: 0.6157 - val_loss: 0.7375 - val_accuracy: 0.5618\n",
            "Epoch 704/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6181 - val_loss: 0.7589 - val_accuracy: 0.5610\n",
            "Epoch 705/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6179 - accuracy: 0.6196 - val_loss: 0.7572 - val_accuracy: 0.5614\n",
            "Epoch 706/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6176 - accuracy: 0.6200 - val_loss: 0.7619 - val_accuracy: 0.5599\n",
            "Epoch 707/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6186 - accuracy: 0.6213 - val_loss: 0.7639 - val_accuracy: 0.5618\n",
            "Epoch 708/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.6196 - val_loss: 0.7770 - val_accuracy: 0.5622\n",
            "Epoch 709/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6204 - val_loss: 0.7803 - val_accuracy: 0.5660\n",
            "Epoch 710/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6153 - accuracy: 0.6206 - val_loss: 0.7852 - val_accuracy: 0.5675\n",
            "Epoch 711/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6191 - val_loss: 0.7838 - val_accuracy: 0.5618\n",
            "Epoch 712/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.6208 - val_loss: 0.7569 - val_accuracy: 0.5641\n",
            "Epoch 713/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6169 - accuracy: 0.6163 - val_loss: 0.7664 - val_accuracy: 0.5645\n",
            "Epoch 714/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6171 - accuracy: 0.6165 - val_loss: 0.7861 - val_accuracy: 0.5679\n",
            "Epoch 715/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.6137 - val_loss: 0.7752 - val_accuracy: 0.5595\n",
            "Epoch 716/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6197 - accuracy: 0.6163 - val_loss: 0.7764 - val_accuracy: 0.5561\n",
            "Epoch 717/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.6147 - val_loss: 0.8039 - val_accuracy: 0.5622\n",
            "Epoch 718/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6330 - accuracy: 0.6165 - val_loss: 0.7584 - val_accuracy: 0.5668\n",
            "Epoch 719/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6266 - accuracy: 0.6170 - val_loss: 0.7535 - val_accuracy: 0.5649\n",
            "Epoch 720/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6218 - accuracy: 0.6139 - val_loss: 0.7672 - val_accuracy: 0.5584\n",
            "Epoch 721/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6191 - accuracy: 0.6166 - val_loss: 0.7827 - val_accuracy: 0.5641\n",
            "Epoch 722/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6180 - val_loss: 0.7842 - val_accuracy: 0.5637\n",
            "Epoch 723/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.6165 - val_loss: 0.7786 - val_accuracy: 0.5664\n",
            "Epoch 724/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6165 - accuracy: 0.6206 - val_loss: 0.7700 - val_accuracy: 0.5649\n",
            "Epoch 725/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6255 - accuracy: 0.6176 - val_loss: 0.7879 - val_accuracy: 0.5717\n",
            "Epoch 726/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6198 - accuracy: 0.6167 - val_loss: 0.7660 - val_accuracy: 0.5633\n",
            "Epoch 727/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6195 - accuracy: 0.6186 - val_loss: 0.7470 - val_accuracy: 0.5668\n",
            "Epoch 728/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.6161 - val_loss: 0.7628 - val_accuracy: 0.5660\n",
            "Epoch 729/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.6172 - val_loss: 0.7711 - val_accuracy: 0.5664\n",
            "Epoch 730/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6173 - accuracy: 0.6196 - val_loss: 0.7738 - val_accuracy: 0.5675\n",
            "Epoch 731/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.6168 - val_loss: 0.7690 - val_accuracy: 0.5630\n",
            "Epoch 732/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6169 - accuracy: 0.6200 - val_loss: 0.7856 - val_accuracy: 0.5736\n",
            "Epoch 733/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6191 - accuracy: 0.6184 - val_loss: 0.7768 - val_accuracy: 0.5652\n",
            "Epoch 734/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6184 - val_loss: 0.7747 - val_accuracy: 0.5664\n",
            "Epoch 735/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6222 - accuracy: 0.6137 - val_loss: 0.7621 - val_accuracy: 0.5690\n",
            "Epoch 736/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6245 - accuracy: 0.6157 - val_loss: 0.7986 - val_accuracy: 0.5641\n",
            "Epoch 737/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6223 - accuracy: 0.6173 - val_loss: 0.7745 - val_accuracy: 0.5713\n",
            "Epoch 738/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6153 - accuracy: 0.6180 - val_loss: 0.7837 - val_accuracy: 0.5645\n",
            "Epoch 739/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6166 - accuracy: 0.6175 - val_loss: 0.7778 - val_accuracy: 0.5633\n",
            "Epoch 740/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6136 - accuracy: 0.6189 - val_loss: 0.7791 - val_accuracy: 0.5679\n",
            "Epoch 741/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6199 - val_loss: 0.7490 - val_accuracy: 0.5744\n",
            "Epoch 742/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6278 - accuracy: 0.6142 - val_loss: 0.7730 - val_accuracy: 0.5687\n",
            "Epoch 743/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6138 - val_loss: 0.7764 - val_accuracy: 0.5656\n",
            "Epoch 744/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6171 - accuracy: 0.6181 - val_loss: 0.7571 - val_accuracy: 0.5641\n",
            "Epoch 745/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6206 - val_loss: 0.7675 - val_accuracy: 0.5656\n",
            "Epoch 746/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.6167 - val_loss: 0.7772 - val_accuracy: 0.5652\n",
            "Epoch 747/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6129 - accuracy: 0.6187 - val_loss: 0.7667 - val_accuracy: 0.5610\n",
            "Epoch 748/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6118 - accuracy: 0.6200 - val_loss: 0.7764 - val_accuracy: 0.5626\n",
            "Epoch 749/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6141 - accuracy: 0.6161 - val_loss: 0.7709 - val_accuracy: 0.5649\n",
            "Epoch 750/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6158 - accuracy: 0.6170 - val_loss: 0.7616 - val_accuracy: 0.5652\n",
            "Epoch 751/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6180 - val_loss: 0.7448 - val_accuracy: 0.5633\n",
            "Epoch 752/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6206 - accuracy: 0.6165 - val_loss: 0.7716 - val_accuracy: 0.5683\n",
            "Epoch 753/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6177 - val_loss: 0.7514 - val_accuracy: 0.5694\n",
            "Epoch 754/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6266 - accuracy: 0.6198 - val_loss: 0.7473 - val_accuracy: 0.5645\n",
            "Epoch 755/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6327 - accuracy: 0.6182 - val_loss: 0.7543 - val_accuracy: 0.5698\n",
            "Epoch 756/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6281 - accuracy: 0.6187 - val_loss: 0.7523 - val_accuracy: 0.5683\n",
            "Epoch 757/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.6179 - val_loss: 0.7677 - val_accuracy: 0.5668\n",
            "Epoch 758/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.6204 - val_loss: 0.7603 - val_accuracy: 0.5709\n",
            "Epoch 759/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6205 - val_loss: 0.7843 - val_accuracy: 0.5652\n",
            "Epoch 760/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.6201 - val_loss: 0.7829 - val_accuracy: 0.5641\n",
            "Epoch 761/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6229 - val_loss: 0.7517 - val_accuracy: 0.5683\n",
            "Epoch 762/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6208 - accuracy: 0.6190 - val_loss: 0.7701 - val_accuracy: 0.5683\n",
            "Epoch 763/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6178 - accuracy: 0.6185 - val_loss: 0.7964 - val_accuracy: 0.5683\n",
            "Epoch 764/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.6214 - val_loss: 0.8026 - val_accuracy: 0.5683\n",
            "Epoch 765/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.6187 - val_loss: 0.7837 - val_accuracy: 0.5633\n",
            "Epoch 766/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6198 - accuracy: 0.6199 - val_loss: 0.7432 - val_accuracy: 0.5641\n",
            "Epoch 767/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6367 - accuracy: 0.6189 - val_loss: 0.7237 - val_accuracy: 0.5747\n",
            "Epoch 768/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6259 - accuracy: 0.6186 - val_loss: 0.7574 - val_accuracy: 0.5747\n",
            "Epoch 769/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6184 - val_loss: 0.7483 - val_accuracy: 0.5690\n",
            "Epoch 770/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.6205 - val_loss: 0.7633 - val_accuracy: 0.5694\n",
            "Epoch 771/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.6211 - val_loss: 0.7545 - val_accuracy: 0.5645\n",
            "Epoch 772/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6171 - val_loss: 0.7940 - val_accuracy: 0.5747\n",
            "Epoch 773/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6194 - val_loss: 0.7973 - val_accuracy: 0.5698\n",
            "Epoch 774/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6185 - val_loss: 0.7911 - val_accuracy: 0.5660\n",
            "Epoch 775/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6167 - val_loss: 0.7733 - val_accuracy: 0.5664\n",
            "Epoch 776/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6194 - val_loss: 0.7747 - val_accuracy: 0.5622\n",
            "Epoch 777/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.6167 - val_loss: 0.7696 - val_accuracy: 0.5690\n",
            "Epoch 778/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.6210 - val_loss: 0.7555 - val_accuracy: 0.5690\n",
            "Epoch 779/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6203 - val_loss: 0.7829 - val_accuracy: 0.5687\n",
            "Epoch 780/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.6181 - val_loss: 0.7921 - val_accuracy: 0.5641\n",
            "Epoch 781/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6238 - val_loss: 0.7624 - val_accuracy: 0.5664\n",
            "Epoch 782/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.6157 - val_loss: 0.7717 - val_accuracy: 0.5607\n",
            "Epoch 783/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.6170 - val_loss: 0.7753 - val_accuracy: 0.5607\n",
            "Epoch 784/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.6194 - val_loss: 0.7911 - val_accuracy: 0.5607\n",
            "Epoch 785/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.6191 - val_loss: 0.7904 - val_accuracy: 0.5660\n",
            "Epoch 786/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6148 - accuracy: 0.6184 - val_loss: 0.7753 - val_accuracy: 0.5687\n",
            "Epoch 787/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6203 - val_loss: 0.7887 - val_accuracy: 0.5630\n",
            "Epoch 788/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6189 - val_loss: 0.8236 - val_accuracy: 0.5610\n",
            "Epoch 789/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6187 - accuracy: 0.6200 - val_loss: 0.7884 - val_accuracy: 0.5637\n",
            "Epoch 790/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6204 - val_loss: 0.7908 - val_accuracy: 0.5637\n",
            "Epoch 791/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.6196 - val_loss: 0.7843 - val_accuracy: 0.5675\n",
            "Epoch 792/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6178 - accuracy: 0.6208 - val_loss: 0.7812 - val_accuracy: 0.5645\n",
            "Epoch 793/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6187 - accuracy: 0.6191 - val_loss: 0.7903 - val_accuracy: 0.5641\n",
            "Epoch 794/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6198 - accuracy: 0.6200 - val_loss: 0.8046 - val_accuracy: 0.5675\n",
            "Epoch 795/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6225 - accuracy: 0.6228 - val_loss: 0.7562 - val_accuracy: 0.5744\n",
            "Epoch 796/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6257 - accuracy: 0.6177 - val_loss: 0.7998 - val_accuracy: 0.5626\n",
            "Epoch 797/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6200 - val_loss: 0.7818 - val_accuracy: 0.5622\n",
            "Epoch 798/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6191 - accuracy: 0.6189 - val_loss: 0.7953 - val_accuracy: 0.5633\n",
            "Epoch 799/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6309 - accuracy: 0.6201 - val_loss: 0.8099 - val_accuracy: 0.5671\n",
            "Epoch 800/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.6173 - val_loss: 0.7694 - val_accuracy: 0.5668\n",
            "Epoch 801/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6248 - accuracy: 0.6171 - val_loss: 0.8000 - val_accuracy: 0.5633\n",
            "Epoch 802/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.6206 - val_loss: 0.7825 - val_accuracy: 0.5633\n",
            "Epoch 803/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6264 - accuracy: 0.6179 - val_loss: 0.7794 - val_accuracy: 0.5607\n",
            "Epoch 804/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.6194 - val_loss: 0.7804 - val_accuracy: 0.5630\n",
            "Epoch 805/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6176 - accuracy: 0.6204 - val_loss: 0.7846 - val_accuracy: 0.5633\n",
            "Epoch 806/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6217 - val_loss: 0.7667 - val_accuracy: 0.5633\n",
            "Epoch 807/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6138 - accuracy: 0.6210 - val_loss: 0.7796 - val_accuracy: 0.5622\n",
            "Epoch 808/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6127 - accuracy: 0.6209 - val_loss: 0.7727 - val_accuracy: 0.5614\n",
            "Epoch 809/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6135 - accuracy: 0.6210 - val_loss: 0.7766 - val_accuracy: 0.5626\n",
            "Epoch 810/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6205 - val_loss: 0.7618 - val_accuracy: 0.5626\n",
            "Epoch 811/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.6208 - val_loss: 0.7697 - val_accuracy: 0.5641\n",
            "Epoch 812/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6171 - accuracy: 0.6167 - val_loss: 0.7803 - val_accuracy: 0.5717\n",
            "Epoch 813/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6229 - accuracy: 0.6186 - val_loss: 0.7488 - val_accuracy: 0.5679\n",
            "Epoch 814/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6206 - accuracy: 0.6191 - val_loss: 0.7671 - val_accuracy: 0.5713\n",
            "Epoch 815/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.6192 - val_loss: 0.7588 - val_accuracy: 0.5721\n",
            "Epoch 816/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6176 - accuracy: 0.6196 - val_loss: 0.7668 - val_accuracy: 0.5725\n",
            "Epoch 817/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6176 - accuracy: 0.6203 - val_loss: 0.7846 - val_accuracy: 0.5633\n",
            "Epoch 818/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6231 - val_loss: 0.7764 - val_accuracy: 0.5679\n",
            "Epoch 819/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6158 - val_loss: 0.7845 - val_accuracy: 0.5732\n",
            "Epoch 820/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.6210 - val_loss: 0.7929 - val_accuracy: 0.5660\n",
            "Epoch 821/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6156 - accuracy: 0.6204 - val_loss: 0.8189 - val_accuracy: 0.5630\n",
            "Epoch 822/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6133 - accuracy: 0.6222 - val_loss: 0.8245 - val_accuracy: 0.5610\n",
            "Epoch 823/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6169 - accuracy: 0.6205 - val_loss: 0.8100 - val_accuracy: 0.5633\n",
            "Epoch 824/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.6201 - val_loss: 0.8247 - val_accuracy: 0.5641\n",
            "Epoch 825/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6136 - accuracy: 0.6194 - val_loss: 0.8092 - val_accuracy: 0.5637\n",
            "Epoch 826/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6204 - accuracy: 0.6179 - val_loss: 0.7769 - val_accuracy: 0.5683\n",
            "Epoch 827/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6268 - accuracy: 0.6138 - val_loss: 0.7855 - val_accuracy: 0.5652\n",
            "Epoch 828/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6176 - val_loss: 0.7829 - val_accuracy: 0.5649\n",
            "Epoch 829/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6179 - val_loss: 0.7718 - val_accuracy: 0.5641\n",
            "Epoch 830/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6198 - val_loss: 0.7716 - val_accuracy: 0.5626\n",
            "Epoch 831/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6208 - accuracy: 0.6189 - val_loss: 0.7927 - val_accuracy: 0.5652\n",
            "Epoch 832/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.6211 - val_loss: 0.8054 - val_accuracy: 0.5649\n",
            "Epoch 833/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6159 - accuracy: 0.6210 - val_loss: 0.8096 - val_accuracy: 0.5633\n",
            "Epoch 834/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6204 - val_loss: 0.7667 - val_accuracy: 0.5603\n",
            "Epoch 835/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6262 - accuracy: 0.6166 - val_loss: 0.8260 - val_accuracy: 0.5626\n",
            "Epoch 836/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6297 - accuracy: 0.6189 - val_loss: 0.7519 - val_accuracy: 0.5694\n",
            "Epoch 837/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6262 - accuracy: 0.6156 - val_loss: 0.7799 - val_accuracy: 0.5607\n",
            "Epoch 838/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6227 - accuracy: 0.6185 - val_loss: 0.7819 - val_accuracy: 0.5626\n",
            "Epoch 839/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6219 - val_loss: 0.7862 - val_accuracy: 0.5671\n",
            "Epoch 840/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6165 - accuracy: 0.6204 - val_loss: 0.7689 - val_accuracy: 0.5660\n",
            "Epoch 841/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6202 - accuracy: 0.6115 - val_loss: 0.7799 - val_accuracy: 0.5702\n",
            "Epoch 842/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6171 - accuracy: 0.6195 - val_loss: 0.7805 - val_accuracy: 0.5630\n",
            "Epoch 843/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.6204 - val_loss: 0.7806 - val_accuracy: 0.5622\n",
            "Epoch 844/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6133 - accuracy: 0.6215 - val_loss: 0.7915 - val_accuracy: 0.5645\n",
            "Epoch 845/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6273 - accuracy: 0.6195 - val_loss: 0.7492 - val_accuracy: 0.5671\n",
            "Epoch 846/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6177 - val_loss: 0.7591 - val_accuracy: 0.5702\n",
            "Epoch 847/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.6168 - val_loss: 0.7465 - val_accuracy: 0.5687\n",
            "Epoch 848/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.6201 - val_loss: 0.7661 - val_accuracy: 0.5618\n",
            "Epoch 849/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6135 - val_loss: 0.7744 - val_accuracy: 0.5622\n",
            "Epoch 850/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6138 - accuracy: 0.6209 - val_loss: 0.7658 - val_accuracy: 0.5618\n",
            "Epoch 851/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6134 - accuracy: 0.6191 - val_loss: 0.7464 - val_accuracy: 0.5637\n",
            "Epoch 852/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6140 - accuracy: 0.6199 - val_loss: 0.7637 - val_accuracy: 0.5645\n",
            "Epoch 853/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.6123 - val_loss: 0.7801 - val_accuracy: 0.5649\n",
            "Epoch 854/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6282 - accuracy: 0.6149 - val_loss: 0.7882 - val_accuracy: 0.5702\n",
            "Epoch 855/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6279 - accuracy: 0.6189 - val_loss: 0.7844 - val_accuracy: 0.5694\n",
            "Epoch 856/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6189 - val_loss: 0.7812 - val_accuracy: 0.5698\n",
            "Epoch 857/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6233 - val_loss: 0.8004 - val_accuracy: 0.5706\n",
            "Epoch 858/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6203 - val_loss: 0.7745 - val_accuracy: 0.5728\n",
            "Epoch 859/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6133 - val_loss: 0.7853 - val_accuracy: 0.5668\n",
            "Epoch 860/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6174 - accuracy: 0.6210 - val_loss: 0.7926 - val_accuracy: 0.5679\n",
            "Epoch 861/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6158 - accuracy: 0.6192 - val_loss: 0.7984 - val_accuracy: 0.5679\n",
            "Epoch 862/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6142 - accuracy: 0.6199 - val_loss: 0.7683 - val_accuracy: 0.5637\n",
            "Epoch 863/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6140 - accuracy: 0.6232 - val_loss: 0.8414 - val_accuracy: 0.5641\n",
            "Epoch 864/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6202 - accuracy: 0.6189 - val_loss: 0.7747 - val_accuracy: 0.5668\n",
            "Epoch 865/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6197 - accuracy: 0.6181 - val_loss: 0.7776 - val_accuracy: 0.5721\n",
            "Epoch 866/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.6205 - val_loss: 0.7819 - val_accuracy: 0.5664\n",
            "Epoch 867/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6145 - accuracy: 0.6225 - val_loss: 0.7832 - val_accuracy: 0.5671\n",
            "Epoch 868/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6133 - accuracy: 0.6220 - val_loss: 0.7787 - val_accuracy: 0.5637\n",
            "Epoch 869/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6143 - accuracy: 0.6181 - val_loss: 0.8003 - val_accuracy: 0.5630\n",
            "Epoch 870/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6173 - val_loss: 0.7671 - val_accuracy: 0.5702\n",
            "Epoch 871/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6262 - accuracy: 0.6158 - val_loss: 0.7707 - val_accuracy: 0.5664\n",
            "Epoch 872/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6294 - accuracy: 0.6196 - val_loss: 0.7681 - val_accuracy: 0.5660\n",
            "Epoch 873/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6213 - val_loss: 0.7843 - val_accuracy: 0.5630\n",
            "Epoch 874/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6206 - accuracy: 0.6205 - val_loss: 0.7755 - val_accuracy: 0.5668\n",
            "Epoch 875/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.6201 - val_loss: 0.7806 - val_accuracy: 0.5660\n",
            "Epoch 876/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6187 - val_loss: 0.7701 - val_accuracy: 0.5656\n",
            "Epoch 877/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6171 - val_loss: 0.7809 - val_accuracy: 0.5652\n",
            "Epoch 878/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6191 - val_loss: 0.7577 - val_accuracy: 0.5649\n",
            "Epoch 879/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.6192 - val_loss: 0.7721 - val_accuracy: 0.5679\n",
            "Epoch 880/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6195 - val_loss: 0.7438 - val_accuracy: 0.5671\n",
            "Epoch 881/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6198 - val_loss: 0.7638 - val_accuracy: 0.5675\n",
            "Epoch 882/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6231 - accuracy: 0.6201 - val_loss: 0.7604 - val_accuracy: 0.5671\n",
            "Epoch 883/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6222 - val_loss: 0.7657 - val_accuracy: 0.5668\n",
            "Epoch 884/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6165 - accuracy: 0.6215 - val_loss: 0.7719 - val_accuracy: 0.5668\n",
            "Epoch 885/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.6205 - val_loss: 0.7751 - val_accuracy: 0.5675\n",
            "Epoch 886/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6206 - val_loss: 0.7414 - val_accuracy: 0.5671\n",
            "Epoch 887/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6202 - accuracy: 0.6206 - val_loss: 0.7619 - val_accuracy: 0.5641\n",
            "Epoch 888/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6171 - accuracy: 0.6190 - val_loss: 0.7790 - val_accuracy: 0.5641\n",
            "Epoch 889/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6160 - accuracy: 0.6217 - val_loss: 0.7888 - val_accuracy: 0.5668\n",
            "Epoch 890/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6158 - accuracy: 0.6222 - val_loss: 0.7912 - val_accuracy: 0.5675\n",
            "Epoch 891/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6307 - accuracy: 0.6158 - val_loss: 0.8144 - val_accuracy: 0.5671\n",
            "Epoch 892/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6331 - accuracy: 0.6187 - val_loss: 0.7892 - val_accuracy: 0.5633\n",
            "Epoch 893/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6247 - accuracy: 0.6186 - val_loss: 0.8154 - val_accuracy: 0.5626\n",
            "Epoch 894/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6203 - val_loss: 0.8159 - val_accuracy: 0.5630\n",
            "Epoch 895/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.6210 - val_loss: 0.7970 - val_accuracy: 0.5637\n",
            "Epoch 896/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.6198 - val_loss: 0.8073 - val_accuracy: 0.5637\n",
            "Epoch 897/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.6167 - val_loss: 0.7935 - val_accuracy: 0.5637\n",
            "Epoch 898/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6197 - accuracy: 0.6205 - val_loss: 0.7864 - val_accuracy: 0.5645\n",
            "Epoch 899/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6220 - val_loss: 0.8013 - val_accuracy: 0.5603\n",
            "Epoch 900/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6191 - accuracy: 0.6170 - val_loss: 0.7990 - val_accuracy: 0.5671\n",
            "Epoch 901/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.6194 - val_loss: 0.8081 - val_accuracy: 0.5671\n",
            "Epoch 902/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6176 - val_loss: 0.8089 - val_accuracy: 0.5622\n",
            "Epoch 903/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6204 - val_loss: 0.7679 - val_accuracy: 0.5641\n",
            "Epoch 904/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6262 - accuracy: 0.6171 - val_loss: 0.7908 - val_accuracy: 0.5630\n",
            "Epoch 905/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6191 - val_loss: 0.7667 - val_accuracy: 0.5618\n",
            "Epoch 906/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6190 - accuracy: 0.6187 - val_loss: 0.7838 - val_accuracy: 0.5618\n",
            "Epoch 907/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6169 - accuracy: 0.6225 - val_loss: 0.7842 - val_accuracy: 0.5626\n",
            "Epoch 908/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.6180 - val_loss: 0.7720 - val_accuracy: 0.5599\n",
            "Epoch 909/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.6196 - val_loss: 0.8113 - val_accuracy: 0.5603\n",
            "Epoch 910/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6194 - accuracy: 0.6179 - val_loss: 0.8036 - val_accuracy: 0.5603\n",
            "Epoch 911/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.6168 - val_loss: 0.8033 - val_accuracy: 0.5633\n",
            "Epoch 912/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6190 - val_loss: 0.7889 - val_accuracy: 0.5668\n",
            "Epoch 913/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6149 - accuracy: 0.6208 - val_loss: 0.7999 - val_accuracy: 0.5656\n",
            "Epoch 914/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6211 - val_loss: 0.7488 - val_accuracy: 0.5656\n",
            "Epoch 915/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6268 - accuracy: 0.6182 - val_loss: 0.7627 - val_accuracy: 0.5664\n",
            "Epoch 916/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6319 - accuracy: 0.6170 - val_loss: 0.7790 - val_accuracy: 0.5664\n",
            "Epoch 917/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6261 - accuracy: 0.6162 - val_loss: 0.7879 - val_accuracy: 0.5668\n",
            "Epoch 918/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6194 - accuracy: 0.6192 - val_loss: 0.7862 - val_accuracy: 0.5660\n",
            "Epoch 919/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.6223 - val_loss: 0.7544 - val_accuracy: 0.5664\n",
            "Epoch 920/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6213 - val_loss: 0.7676 - val_accuracy: 0.5641\n",
            "Epoch 921/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6172 - val_loss: 0.7739 - val_accuracy: 0.5687\n",
            "Epoch 922/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6194 - accuracy: 0.6182 - val_loss: 0.7682 - val_accuracy: 0.5675\n",
            "Epoch 923/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6180 - accuracy: 0.6204 - val_loss: 0.7758 - val_accuracy: 0.5702\n",
            "Epoch 924/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6182 - val_loss: 0.7785 - val_accuracy: 0.5721\n",
            "Epoch 925/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.6172 - val_loss: 0.7548 - val_accuracy: 0.5671\n",
            "Epoch 926/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.6215 - val_loss: 0.7560 - val_accuracy: 0.5694\n",
            "Epoch 927/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.6192 - val_loss: 0.7617 - val_accuracy: 0.5679\n",
            "Epoch 928/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.6171 - val_loss: 0.7722 - val_accuracy: 0.5660\n",
            "Epoch 929/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.6182 - val_loss: 0.7626 - val_accuracy: 0.5633\n",
            "Epoch 930/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6176 - accuracy: 0.6217 - val_loss: 0.7735 - val_accuracy: 0.5652\n",
            "Epoch 931/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6198 - accuracy: 0.6153 - val_loss: 0.7680 - val_accuracy: 0.5683\n",
            "Epoch 932/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6271 - accuracy: 0.6177 - val_loss: 0.7949 - val_accuracy: 0.5671\n",
            "Epoch 933/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6266 - accuracy: 0.6200 - val_loss: 0.7866 - val_accuracy: 0.5671\n",
            "Epoch 934/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6215 - accuracy: 0.6218 - val_loss: 0.7918 - val_accuracy: 0.5675\n",
            "Epoch 935/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6215 - val_loss: 0.7865 - val_accuracy: 0.5668\n",
            "Epoch 936/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6223 - val_loss: 0.8020 - val_accuracy: 0.5736\n",
            "Epoch 937/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6156 - accuracy: 0.6200 - val_loss: 0.7873 - val_accuracy: 0.5725\n",
            "Epoch 938/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6227 - accuracy: 0.6203 - val_loss: 0.8131 - val_accuracy: 0.5721\n",
            "Epoch 939/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.6200 - val_loss: 0.7880 - val_accuracy: 0.5732\n",
            "Epoch 940/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.6200 - val_loss: 0.8143 - val_accuracy: 0.5675\n",
            "Epoch 941/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6165 - accuracy: 0.6217 - val_loss: 0.7843 - val_accuracy: 0.5668\n",
            "Epoch 942/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.6213 - val_loss: 0.8045 - val_accuracy: 0.5660\n",
            "Epoch 943/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6217 - val_loss: 0.7970 - val_accuracy: 0.5675\n",
            "Epoch 944/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.6211 - val_loss: 0.7975 - val_accuracy: 0.5664\n",
            "Epoch 945/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6215 - val_loss: 0.8425 - val_accuracy: 0.5664\n",
            "Epoch 946/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6192 - val_loss: 0.7607 - val_accuracy: 0.5671\n",
            "Epoch 947/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.6162 - val_loss: 0.8367 - val_accuracy: 0.5671\n",
            "Epoch 948/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6257 - accuracy: 0.6203 - val_loss: 0.7926 - val_accuracy: 0.5668\n",
            "Epoch 949/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6209 - val_loss: 0.7925 - val_accuracy: 0.5641\n",
            "Epoch 950/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.6190 - val_loss: 0.7698 - val_accuracy: 0.5671\n",
            "Epoch 951/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.6211 - val_loss: 0.8125 - val_accuracy: 0.5664\n",
            "Epoch 952/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.6222 - val_loss: 0.8077 - val_accuracy: 0.5668\n",
            "Epoch 953/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.6213 - val_loss: 0.8294 - val_accuracy: 0.5462\n",
            "Epoch 954/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6191 - val_loss: 0.7537 - val_accuracy: 0.5687\n",
            "Epoch 955/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6274 - accuracy: 0.6206 - val_loss: 0.7734 - val_accuracy: 0.5668\n",
            "Epoch 956/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6246 - accuracy: 0.6204 - val_loss: 0.7386 - val_accuracy: 0.5671\n",
            "Epoch 957/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.6210 - val_loss: 0.7529 - val_accuracy: 0.5668\n",
            "Epoch 958/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6201 - accuracy: 0.6217 - val_loss: 0.7484 - val_accuracy: 0.5732\n",
            "Epoch 959/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6225 - accuracy: 0.6208 - val_loss: 0.7442 - val_accuracy: 0.5679\n",
            "Epoch 960/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6211 - val_loss: 0.7563 - val_accuracy: 0.5675\n",
            "Epoch 961/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6206 - val_loss: 0.7521 - val_accuracy: 0.5675\n",
            "Epoch 962/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6209 - accuracy: 0.6220 - val_loss: 0.7506 - val_accuracy: 0.5698\n",
            "Epoch 963/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6196 - accuracy: 0.6166 - val_loss: 0.7666 - val_accuracy: 0.5656\n",
            "Epoch 964/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6165 - accuracy: 0.6179 - val_loss: 0.7791 - val_accuracy: 0.5626\n",
            "Epoch 965/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6156 - accuracy: 0.6224 - val_loss: 0.7636 - val_accuracy: 0.5649\n",
            "Epoch 966/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.6181 - val_loss: 0.7354 - val_accuracy: 0.5618\n",
            "Epoch 967/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6243 - accuracy: 0.6185 - val_loss: 0.7788 - val_accuracy: 0.5637\n",
            "Epoch 968/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6261 - accuracy: 0.6156 - val_loss: 0.8035 - val_accuracy: 0.5668\n",
            "Epoch 969/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6268 - accuracy: 0.6160 - val_loss: 0.7789 - val_accuracy: 0.5717\n",
            "Epoch 970/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.6166 - val_loss: 0.7779 - val_accuracy: 0.5732\n",
            "Epoch 971/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6246 - accuracy: 0.6158 - val_loss: 0.7707 - val_accuracy: 0.5664\n",
            "Epoch 972/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6189 - accuracy: 0.6191 - val_loss: 0.7778 - val_accuracy: 0.5664\n",
            "Epoch 973/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6185 - val_loss: 0.7773 - val_accuracy: 0.5770\n",
            "Epoch 974/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6245 - accuracy: 0.6138 - val_loss: 0.7719 - val_accuracy: 0.5763\n",
            "Epoch 975/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6225 - accuracy: 0.6166 - val_loss: 0.7808 - val_accuracy: 0.5770\n",
            "Epoch 976/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.6199 - val_loss: 0.8004 - val_accuracy: 0.5732\n",
            "Epoch 977/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.6181 - val_loss: 0.7975 - val_accuracy: 0.5622\n",
            "Epoch 978/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6142 - accuracy: 0.6231 - val_loss: 0.7834 - val_accuracy: 0.5664\n",
            "Epoch 979/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6208 - val_loss: 0.7962 - val_accuracy: 0.5671\n",
            "Epoch 980/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6176 - val_loss: 0.7893 - val_accuracy: 0.5641\n",
            "Epoch 981/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6173 - accuracy: 0.6190 - val_loss: 0.8037 - val_accuracy: 0.5622\n",
            "Epoch 982/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6211 - val_loss: 0.8177 - val_accuracy: 0.5660\n",
            "Epoch 983/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.6200 - val_loss: 0.8242 - val_accuracy: 0.5630\n",
            "Epoch 984/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6208 - val_loss: 0.8086 - val_accuracy: 0.5637\n",
            "Epoch 985/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6249 - accuracy: 0.6201 - val_loss: 0.7621 - val_accuracy: 0.5649\n",
            "Epoch 986/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6301 - accuracy: 0.6170 - val_loss: 0.7914 - val_accuracy: 0.5618\n",
            "Epoch 987/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.6195 - val_loss: 0.8148 - val_accuracy: 0.5641\n",
            "Epoch 988/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6205 - val_loss: 0.8127 - val_accuracy: 0.5668\n",
            "Epoch 989/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6199 - val_loss: 0.8307 - val_accuracy: 0.5668\n",
            "Epoch 990/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.6211 - val_loss: 0.8266 - val_accuracy: 0.5668\n",
            "Epoch 991/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.6218 - val_loss: 0.8233 - val_accuracy: 0.5660\n",
            "Epoch 992/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6154 - accuracy: 0.6214 - val_loss: 0.8180 - val_accuracy: 0.5709\n",
            "Epoch 993/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6249 - accuracy: 0.6187 - val_loss: 0.7631 - val_accuracy: 0.5706\n",
            "Epoch 994/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6288 - accuracy: 0.6205 - val_loss: 0.8089 - val_accuracy: 0.5660\n",
            "Epoch 995/1000\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.6257 - accuracy: 0.6199 - val_loss: 0.8359 - val_accuracy: 0.5630\n",
            "Epoch 996/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6247 - accuracy: 0.6195 - val_loss: 0.7864 - val_accuracy: 0.5656\n",
            "Epoch 997/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6297 - accuracy: 0.6214 - val_loss: 0.8042 - val_accuracy: 0.5668\n",
            "Epoch 998/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6229 - accuracy: 0.6210 - val_loss: 0.8425 - val_accuracy: 0.5668\n",
            "Epoch 999/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6209 - accuracy: 0.6206 - val_loss: 0.7875 - val_accuracy: 0.5668\n",
            "Epoch 1000/1000\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.6262 - accuracy: 0.6214 - val_loss: 0.7718 - val_accuracy: 0.5656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction \n",
        "user_id = df_test.user_idx.values\n",
        "product_id = df_test.product_idx.values\n",
        "predictions = model.predict([user_id,product_id])\n",
        "print(predictions[0:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKJ3SsZx0Ysf",
        "outputId": "9bed4566-2a19-4f67-adca-9cbd1906fdd7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.56592906]\n",
            " [0.6029767 ]\n",
            " [0.5164947 ]\n",
            " [0.0047956 ]\n",
            " [0.5164947 ]\n",
            " [0.36406162]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.max())\n",
        "print(predictions.min())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdSZNnkbjwoC",
        "outputId": "3e9127c0-8305-4fd7-87b3-d880488c85ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "3.3187001e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = pd.DataFrame(predictions)"
      ],
      "metadata": {
        "id": "Meg3b-N6o3WF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xiAn5TIGpFcJ",
        "outputId": "7d2ef879-9b69-468f-d3ae-1df6305ff8e2"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0\n",
              "0     5.722258e-01\n",
              "1     6.097581e-01\n",
              "2     5.272503e-01\n",
              "3     4.754068e-07\n",
              "4     5.272503e-01\n",
              "...            ...\n",
              "2624  4.845160e-01\n",
              "2625  4.935139e-01\n",
              "2626  5.722258e-01\n",
              "2627  5.722258e-01\n",
              "2628  5.272503e-01\n",
              "\n",
              "[2629 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76159836-af72-424e-9332-390c63eb3a71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.722258e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.097581e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.272503e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.754068e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.272503e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2624</th>\n",
              "      <td>4.845160e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2625</th>\n",
              "      <td>4.935139e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2626</th>\n",
              "      <td>5.722258e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2627</th>\n",
              "      <td>5.722258e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2628</th>\n",
              "      <td>5.272503e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2629 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76159836-af72-424e-9332-390c63eb3a71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76159836-af72-424e-9332-390c63eb3a71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76159836-af72-424e-9332-390c63eb3a71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[0:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "ECwQJDr4-EdX",
        "outputId": "7d3fd9f7-969e-458b-9b9d-58cf53bce754"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      user_idx  product_idx  rating\n",
              "4044   51022.0         36.0     1.0\n",
              "1192   11564.0        142.0     1.0\n",
              "7929   70633.0       7029.0     1.0\n",
              "658     4835.0         37.0     0.0\n",
              "5019   55956.0        616.0     0.0\n",
              "7512   69049.0        276.0     1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5dd77b1-761b-4ee7-b2c7-24fea7cc8403\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_idx</th>\n",
              "      <th>product_idx</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4044</th>\n",
              "      <td>51022.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1192</th>\n",
              "      <td>11564.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7929</th>\n",
              "      <td>70633.0</td>\n",
              "      <td>7029.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>4835.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5019</th>\n",
              "      <td>55956.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7512</th>\n",
              "      <td>69049.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5dd77b1-761b-4ee7-b2c7-24fea7cc8403')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5dd77b1-761b-4ee7-b2c7-24fea7cc8403 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5dd77b1-761b-4ee7-b2c7-24fea7cc8403');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GWOBDCSXoJoh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "NCF.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}